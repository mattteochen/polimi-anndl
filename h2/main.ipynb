{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuwVgG3Vbbka"
   },
   "source": [
    "# Artificial Neural Networks and Deep Learning\n",
    "\n",
    "---\n",
    "## Homework 2: Image segmentation of Mars' stones\n",
    "## Team: The Backpropagators\n",
    "Arianna Procaccio, Francesco Buccoliero, Kai-Xi Matteo Chen, Luca Capoferri\n",
    "\n",
    "ariii, frbuccoliero, kaiximatteoc, luke01\n",
    "\n",
    "246843, 245498, 245523, 259617\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7IqZP5Iblna"
   },
   "source": [
    "## ‚öôÔ∏è Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T20:59:48.162042Z",
     "iopub.status.busy": "2024-11-21T20:59:48.161808Z",
     "iopub.status.idle": "2024-11-21T20:59:48.172447Z",
     "shell.execute_reply": "2024-11-21T20:59:48.171556Z",
     "shell.execute_reply.started": "2024-11-21T20:59:48.162018Z"
    },
    "id": "CO6_Ft_8T56A",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "#from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T20:59:48.175109Z",
     "iopub.status.busy": "2024-11-21T20:59:48.174259Z",
     "iopub.status.idle": "2024-11-21T20:59:48.181658Z",
     "shell.execute_reply": "2024-11-21T20:59:48.180934Z",
     "shell.execute_reply.started": "2024-11-21T20:59:48.175068Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN_cpHlSboXV"
   },
   "source": [
    "## ‚è≥ Load, inspect and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T20:59:48.205584Z",
     "iopub.status.busy": "2024-11-21T20:59:48.205315Z",
     "iopub.status.idle": "2024-11-21T20:59:48.214590Z",
     "shell.execute_reply": "2024-11-21T20:59:48.213686Z",
     "shell.execute_reply.started": "2024-11-21T20:59:48.205560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"dataset.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T20:59:48.215707Z",
     "iopub.status.busy": "2024-11-21T20:59:48.215465Z",
     "iopub.status.idle": "2024-11-21T20:59:48.226436Z",
     "shell.execute_reply": "2024-11-21T20:59:48.225658Z",
     "shell.execute_reply.started": "2024-11-21T20:59:48.215684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Although we have the test set provided, we don't know their true mask. Reserve a small subset for a known test set to make inference later\n",
    "train_ratio = 0.85\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.05\n",
    "\n",
    "assert train_ratio + validation_ratio + test_ratio == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(DATASET_PATH)\n",
    "\n",
    "training_set = data[\"training_set\"]\n",
    "X_train = training_set[:, 0]\n",
    "y_train = training_set[:, 1]\n",
    "\n",
    "hidden_X_test = data[\"test_set\"]\n",
    "\n",
    "print(f\"Training X shape: {X_train.shape}\")\n",
    "print(f\"Training y shape: {y_train.shape}\")\n",
    "print(f\"Test hidden X shape: {hidden_X_test.shape}\")\n",
    "\n",
    "# Add color channel and rescale pixels between 0 and 1\n",
    "X_train = X_train[..., np.newaxis] / 255\n",
    "X_train = X_train.astype(np.float32)\n",
    "hidden_X_test = hidden_X_test[..., np.newaxis] / 255\n",
    "hidden_X_test = hidden_X_test.astype(np.float32)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and validation\n",
    "validation_size = int(X_train.shape[0] * validation_ratio)\n",
    "\n",
    "indices = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X_train = X_train[indices]\n",
    "y_train = y_train[indices]\n",
    "\n",
    "# Define train and validation indices\n",
    "split_indices = [int(X_train.shape[0] * train_ratio), int(X_train.shape[0] * (train_ratio + validation_ratio))]\n",
    "\n",
    "X_train, X_val, X_test = np.split(X_train, split_indices)\n",
    "y_train, y_val, y_test = np.split(y_train, split_indices)\n",
    "\n",
    "print(f\"Training X shape: {X_train.shape}\")\n",
    "print(f\"Training y shape: {y_train.shape}\")\n",
    "print(f\"Validation X shape: {X_val.shape}\")\n",
    "print(f\"Validation y shape: {y_val.shape}\")\n",
    "print(f\"Test X shape: {X_test.shape}\")\n",
    "print(f\"Test y shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data. The number of images being displayed are rows X cols\n",
    "def plot(data, mask=None, num_images=10, rows=4, cols=8):\n",
    "  # Reshape if needed (e.g., remove channel dimension for grayscale images)\n",
    "  if data.shape[-1] == 1:  # Grayscale case\n",
    "    data = data.squeeze(axis=-1)  # Remove channel dimension\n",
    "  \n",
    "  if mask is None:\n",
    "    # Plot settings\n",
    "    _, axes = plt.subplots(rows, cols, figsize=(12, 6))  # Adjust figure size as needed\n",
    "  \n",
    "    # Display images\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "      if i < len(data):  # Check if there are enough images\n",
    "        ax.imshow(data[i], cmap='gray' if len(data[i].shape) == 2 else None)\n",
    "        ax.axis('off')  # Hide axes\n",
    "      else:\n",
    "        ax.axis('off')  # Hide any empty subplot\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "  else:\n",
    "    num_samples = num_images  # Number of images to display\n",
    "    if num_samples < 4:\n",
    "      num_samples = 4\n",
    "\n",
    "    # Plot settings\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(8, num_samples * 2))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "      # Original image\n",
    "      axes[i, 0].imshow(data[i], cmap=\"gray\")\n",
    "      axes[i, 0].set_title(f\"Image {i+1}\")\n",
    "      axes[i, 0].axis(\"off\")\n",
    "\n",
    "      # Corresponding mask\n",
    "      axes[i, 1].imshow(mask[i], cmap=\"viridis\", alpha=0.8)  # Adjust cmap as needed\n",
    "      axes[i, 1].set_title(f\"Mask {i+1}\")\n",
    "      axes[i, 1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers share the mask\n",
    "outlier_mask_template = np.load(\"outlier_mask.npy\") # discovered by hand\n",
    "train_outliers_indices = [i for i, img in enumerate(y_train) if not np.array_equal(img, outlier_mask_template)]\n",
    "val_outliers_indices = [i for i, img in enumerate(y_val) if not np.array_equal(img, outlier_mask_template)]\n",
    "test_outliers_indices = [i for i, img in enumerate(y_test) if not np.array_equal(img, outlier_mask_template)]\n",
    "print(f'Total outliers in train set: {y_train.shape[0] - len(train_outliers_indices)}')\n",
    "print(f'Total outliers in validation set: {y_val.shape[0] - len(val_outliers_indices)}')\n",
    "print(f'Total outliers in test set: {y_test.shape[0] - len(test_outliers_indices)}')\n",
    "\n",
    "# Remove outlier from train and validation set\n",
    "X_train = X_train[train_outliers_indices]\n",
    "y_train = y_train[train_outliers_indices]\n",
    "X_val = X_val[val_outliers_indices]\n",
    "y_val = y_val[val_outliers_indices]\n",
    "X_test = X_test[test_outliers_indices]\n",
    "y_test = y_test[test_outliers_indices]\n",
    "\n",
    "print(f'Updated train dataset size: {X_train.shape}')\n",
    "print(f'Updated validation dataset size: {X_val.shape}')\n",
    "print(f'Updated test dataset size: {X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(X_train, rows=10, cols=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An additional check: you should not see any outlier\n",
    "plot(X_train, mask=y_train, num_images=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size for the network (dataset size is 64 X 128) and num of classes\n",
    "IMG_SIZE = (64, 128)\n",
    "NUM_CLASSES = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `concat_and_shuffle_aug_with_no_aug` will double the X_train size\n",
    "# `remove_bg` will set all the bg pixels to dark\n",
    "# `augmentation_repetition` will concatenate n times the augmented dataset by applying the same `augmentations` fn. Useful for augmentation pipeline with probability activations\n",
    "def get_dataset(X, y, batch_size=32, augmentations=None, augmentation_repetition=1, **kwargs):\n",
    "  def resize_img_and_mask(img, mask):\n",
    "    input_img = tf.image.resize(img, IMG_SIZE)\n",
    "    input_img = tf.cast(input_img, tf.float32)\n",
    "\n",
    "    # Resize needs at least 3 dims, add a dummy one\n",
    "    target_img = tf.expand_dims(mask, axis=-1)\n",
    "    # Nearest-neighbor is essential for resizing segmentation masks because it preserves the discrete class labels (e.g., 0, 1, 2) without introducing unintended values due to interpolation\n",
    "    target_img = tf.image.resize(target_img, IMG_SIZE, method=\"nearest\")\n",
    "    target_img = tf.cast(target_img, tf.int32) # Consider lower integers\n",
    "\n",
    "    return input_img, target_img\n",
    "\n",
    "  def remove_background(image, mask, background_label=0):\n",
    "    background_mask = (mask == background_label)\n",
    "    image[background_mask] = 0  # Set to black\n",
    "    return image, mask\n",
    "\n",
    "  def apply_augmentation_np():\n",
    "    X_a = []\n",
    "    y_a = []\n",
    "    for i, m in zip(X, y):\n",
    "      aug_img, aug_mask = augmentations(i, m)\n",
    "      if kwargs.get('remove_bg', False):\n",
    "        aug_img, aug_mask = remove_background(aug_img, aug_mask)\n",
    "      X_a.append(aug_img)  \n",
    "      y_a.append(aug_mask)  \n",
    "    return np.array(X_a), np.array(y_a)\n",
    "\n",
    "  if kwargs.get('remove_bg', False):\n",
    "    X_a = []\n",
    "    y_a = []\n",
    "    for i, m in zip(X, y):\n",
    "      aug_img, aug_mask = remove_background(i, m)\n",
    "      X_a.append(aug_img)\n",
    "      y_a.append(aug_mask)\n",
    "    X = np.array(X_a)\n",
    "    y = np.array(y_a)\n",
    "\n",
    "  # Apply augmentations before converting to dataset (this will be serial I think but we avoid type conversions as A works on np arrays)\n",
    "  if augmentations is not None:\n",
    "    X_a, y_a = apply_augmentation_np()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_a, y_a))\n",
    "    if augmentation_repetition > 1:\n",
    "      for i in range(augmentation_repetition-1):\n",
    "        X_a, y_a = apply_augmentation_np()\n",
    "        dataset = dataset.concatenate(tf.data.Dataset.from_tensor_slices((X_a, y_a)))\n",
    "    if kwargs.get('concat_and_shuffle_aug_with_no_aug', False):\n",
    "      dataset = dataset.concatenate(tf.data.Dataset.from_tensor_slices((X, y)))\n",
    "      dataset = dataset.shuffle(seed=seed, buffer_size=X.shape[0] * (augmentation_repetition+1))\n",
    "\n",
    "  else:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "\n",
    "  dataset = dataset.map(resize_img_and_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "  dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## üé≤ Define training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model name. One of:\n",
    "# U_NET\n",
    "# U_NET_XCEPTION\n",
    "# UWNet\n",
    "# ASPP\n",
    "model_name = 'ASPP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T20:59:52.969085Z",
     "iopub.status.busy": "2024-11-21T20:59:52.968811Z",
     "iopub.status.idle": "2024-11-21T20:59:52.978445Z",
     "shell.execute_reply": "2024-11-21T20:59:52.977502Z",
     "shell.execute_reply.started": "2024-11-21T20:59:52.969030Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define training setup\n",
    "epochs = 1000\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T20:59:52.980424Z",
     "iopub.status.busy": "2024-11-21T20:59:52.980176Z",
     "iopub.status.idle": "2024-11-21T20:59:52.990553Z",
     "shell.execute_reply": "2024-11-21T20:59:52.989845Z",
     "shell.execute_reply.started": "2024-11-21T20:59:52.980400Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define optimizer setup\n",
    "lr = 1e-4\n",
    "fine_tuning_lr = 1e-4\n",
    "# One of:\n",
    "# SGD\n",
    "# Adam\n",
    "# AdamW\n",
    "# Lion\n",
    "# Ranger\n",
    "opt_name = \"AdamW\"\n",
    "fine_tuning_opt_name = \"AdamW\"\n",
    "\n",
    "opt_exp_decay_rate: float | None = None\n",
    "# Decay at how many epochs\n",
    "opt_decay_epoch_delta = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "  # Convert y_true to one-hot if needed\n",
    "  # TODO: should we retrieve the argmax and use 1 channels instead of 5?\n",
    "  if y_true.shape[-1] != y_pred.shape[-1]:\n",
    "      y_true = tf.one_hot(tf.cast(y_true[..., 0], tf.int32), depth=y_pred.shape[-1])\n",
    "  \n",
    "  # Compute Dice Loss per class\n",
    "  intersection = tf.reduce_sum(y_true * y_pred, axis=(1, 2))\n",
    "  union = tf.reduce_sum(y_true + y_pred, axis=(1, 2))\n",
    "  dice = (2. * intersection + smooth) / (union + smooth)\n",
    "  \n",
    "  # Average Dice Loss over all classes\n",
    "  dice_loss = 1 - tf.reduce_mean(dice, axis=-1)\n",
    "  return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sparse_categorical_crossentropy when your labels are integers representing class indices\n",
    "loss_fn = 'sparse_categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization callback\n",
    "category_map = {\n",
    "    0: 0, # Background,\n",
    "    1: 1, # Soil,\n",
    "    2: 2, # Bedrock,\n",
    "    3: 3, # Sand,\n",
    "    4: 4, # Big Rock,\n",
    "}\n",
    "\n",
    "def apply_category_mapping(label):\n",
    "    \"\"\"\n",
    "    Apply category mapping to labels.\n",
    "    \"\"\"\n",
    "    print(\"Label dtype before mapping:\", label.dtype)\n",
    "    keys_tensor = tf.constant(list(category_map.keys()), dtype=tf.int32)\n",
    "    vals_tensor = tf.constant(list(category_map.values()), dtype=tf.int32)\n",
    "    table = tf.lookup.StaticHashTable(\n",
    "        tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor),\n",
    "        default_value=0\n",
    "    )\n",
    "    return table.lookup(label)\n",
    "\n",
    "def create_segmentation_colormap(num_classes):\n",
    "    \"\"\"\n",
    "    Create a linear colormap using a predefined palette.\n",
    "    Uses 'viridis' as default because it is perceptually uniform\n",
    "    and works well for colorblindness.\n",
    "    \"\"\"\n",
    "    return plt.cm.viridis(np.linspace(0, 1, num_classes))\n",
    "\n",
    "def apply_colormap(label, colormap=None):\n",
    "    \"\"\"\n",
    "    Apply the colormap to a label.\n",
    "    \"\"\"\n",
    "    # Ensure label is 2D\n",
    "    label = np.squeeze(label)\n",
    "\n",
    "    if colormap is None:\n",
    "        num_classes = len(np.unique(label))\n",
    "        colormap = create_segmentation_colormap(num_classes)\n",
    "\n",
    "    # Apply the colormap\n",
    "    colored = colormap[label.astype(int)]\n",
    "\n",
    "    return colored\n",
    "    \n",
    "class VizCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, image, label, frequency=5):\n",
    "        super().__init__()\n",
    "        self.image = image\n",
    "        self.label = tf.cast(tf.convert_to_tensor(label), tf.int32) \n",
    "        self.frequency = frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.frequency == 0:  # Visualize only every \"frequency\" epochs\n",
    "            image, label = self.image, self.label\n",
    "            label = apply_category_mapping(label)\n",
    "            image = tf.expand_dims(image, 0)\n",
    "            pred = self.model.predict(image, verbose=0)\n",
    "            y_pred = tf.math.argmax(pred, axis=-1)\n",
    "            y_pred = y_pred.numpy()\n",
    "\n",
    "            # Create colormap\n",
    "            num_classes = NUM_CLASSES\n",
    "            colormap = create_segmentation_colormap(num_classes)\n",
    "\n",
    "            plt.figure(figsize=(16, 4))\n",
    "\n",
    "            # Input image\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(image[0],cmap='gray')\n",
    "            plt.title(\"Input Image\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Ground truth\n",
    "            plt.subplot(1, 3, 2)\n",
    "            colored_label = apply_colormap(label.numpy(), colormap)\n",
    "            plt.imshow(colored_label)\n",
    "            plt.title(\"Ground Truth Mask\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Prediction\n",
    "            plt.subplot(1, 3, 3)\n",
    "            colored_pred = apply_colormap(y_pred[0], colormap)\n",
    "            plt.imshow(colored_pred)\n",
    "            plt.title(\"Predicted Mask\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T20:59:53.000513Z",
     "iopub.status.busy": "2024-11-21T20:59:53.000251Z",
     "iopub.status.idle": "2024-11-21T20:59:53.010025Z",
     "shell.execute_reply": "2024-11-21T20:59:53.009423Z",
     "shell.execute_reply.started": "2024-11-21T20:59:53.000489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define fitting callbacks. Comment out from dict the unwanted ones\n",
    "viz_callback = VizCallback(X_val[0], y_val[0]) # to visualize the first image of the validation every 5 epochs\n",
    "model_fit_callbacks = {\n",
    "\t'ReduceLROnPlateau': tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=25, min_lr=1e-6, verbose=1),\n",
    "\t'EarlyStopping': tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=50, restore_best_weights=True, verbose=1),\n",
    "    #'Viz_callback' : viz_callback\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T20:59:53.011207Z",
     "iopub.status.busy": "2024-11-21T20:59:53.010956Z",
     "iopub.status.idle": "2024-11-21T20:59:53.022969Z",
     "shell.execute_reply": "2024-11-21T20:59:53.022102Z",
     "shell.execute_reply.started": "2024-11-21T20:59:53.011183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# just to free or not the memory\n",
    "FREE_MODEL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Define model, augmentation and utils builders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T21:00:06.456714Z",
     "iopub.status.busy": "2024-11-21T21:00:06.456469Z",
     "iopub.status.idle": "2024-11-21T21:00:06.461596Z",
     "shell.execute_reply": "2024-11-21T21:00:06.460618Z",
     "shell.execute_reply.started": "2024-11-21T21:00:06.456690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_augmentation():\n",
    "  transform = A.Compose([\n",
    "          A.RandomRotate90(p=0.7),  # Random 90-degree rotation\n",
    "          A.HorizontalFlip(p=0.7),  # Horizontal flip for diverse texture representation\n",
    "          A.VerticalFlip(p=0.7),  # Vertical flip to simulate different orientations\n",
    "          A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),  # Adjust brightness and contrast\n",
    "          A.GaussianBlur(blur_limit=3, p=0.7),  # Add blur to simulate camera effects\n",
    "          A.CoarseDropout(max_holes=4, max_height=16, max_width=16, p=0.7),  # Randomly occlude parts of the image\n",
    "          A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=45, p=0.7),  # Random shifts, scales, and rotations\n",
    "          A.ElasticTransform(alpha=1, sigma=50, p=0.7),\n",
    "          A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.7),\n",
    "          A.OpticalDistortion(distort_limit=0.2, shift_limit=0.2, p=0.7),\n",
    "          A.Resize(height=IMG_SIZE[0], width=IMG_SIZE[1], p=1),  # Resize for consistent input size\n",
    "      ])\n",
    "  \n",
    "  return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_augmentation(img, mask):\n",
    "  transform = build_augmentation()\n",
    "  transformed = transform(image=img, mask=mask)\n",
    "  return transformed[\"image\"], transformed[\"mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the augmented dataset\n",
    "N = 2\n",
    "ds = get_dataset(X_train[:N], y_train[:N], augmentations=apply_augmentation, augmentation_repetition=4, concat_and_shuffle_aug_with_no_aug=True)\n",
    "\n",
    "for batch in ds.take(1):\n",
    "  a, b = batch\n",
    "  plot(a.numpy(), b.numpy(), num_images=N * 5) # use N * (augmentation_repetition+1) as `concat_and_shuffle_aug_with_no_aug` is True \n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T21:00:15.913190Z",
     "iopub.status.busy": "2024-11-21T21:00:15.912842Z",
     "iopub.status.idle": "2024-11-21T21:00:15.923585Z",
     "shell.execute_reply": "2024-11-21T21:00:15.922710Z",
     "shell.execute_reply.started": "2024-11-21T21:00:15.913155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# taken from https://keras.io/examples/vision/oxford_pets_image_segmentation/\n",
    "def build_U_NET_XCEPTION(img_size: tuple[int, int, int], num_classes):\n",
    "  inputs = tfk.Input(shape=img_size) # One channel input\n",
    "\n",
    "  ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "  # Entry block\n",
    "  x = tfkl.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "  x = tfkl.BatchNormalization()(x)\n",
    "  x = tfkl.Activation(\"relu\")(x)\n",
    "\n",
    "  previous_block_activation = x  # Set aside residual\n",
    "\n",
    "  # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "  for filters in [64, 128, 256]:\n",
    "    x = tfkl.Activation(\"relu\")(x)\n",
    "    x = tfkl.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "\n",
    "    x = tfkl.Activation(\"relu\")(x)\n",
    "    x = tfkl.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "\n",
    "    x = tfkl.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    # Project residual\n",
    "    residual = tfkl.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "    previous_block_activation\n",
    "    )\n",
    "    x = tfkl.add([x, residual])  # Add back residual\n",
    "    previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "  ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "  for filters in [256, 128, 64, 32]:\n",
    "    x = tfkl.Activation(\"relu\")(x)\n",
    "    x = tfkl.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "\n",
    "    x = tfkl.Activation(\"relu\")(x)\n",
    "    x = tfkl.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "\n",
    "    x = tfkl.UpSampling2D(2)(x)\n",
    "\n",
    "    # Project residual\n",
    "    residual = tfkl.UpSampling2D(2)(previous_block_activation)\n",
    "    residual = tfkl.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "    x = tfkl.add([x, residual])  # Add back residual\n",
    "    previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "  # Add a per-pixel classification layer\n",
    "  outputs = tfkl.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "  # Define the model\n",
    "  model = tfk.Model(inputs, outputs, name='UNetXception')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_U_NET(img_size: tuple[int, int, int], num_classes):\n",
    "  def unet_block(input_tensor, filters, kernel_size=3, activation='relu', stack=2, name=''):\n",
    "    # Initialise the input tensor\n",
    "    x = input_tensor\n",
    "\n",
    "    # Apply a sequence of Conv2D, Batch Normalisation, and Activation layers for the specified number of stacks\n",
    "    for i in range(stack):\n",
    "        x = tfkl.Conv2D(filters, kernel_size=kernel_size, padding='same', name=name + 'conv' + str(i + 1))(x)\n",
    "        x = tfkl.BatchNormalization(name=name + 'bn' + str(i + 1))(x)\n",
    "        x = tfkl.Activation(activation, name=name + 'activation' + str(i + 1))(x)\n",
    "\n",
    "    # Return the transformed tensor\n",
    "    return x\n",
    "\n",
    "  input_layer = tfkl.Input(shape=img_size, name='input_layer')\n",
    "\n",
    "  # Downsampling path\n",
    "  down_block_1 = unet_block(input_layer, 32, name='down_block1_')\n",
    "  d1 = tfkl.MaxPooling2D()(down_block_1)\n",
    "\n",
    "  down_block_2 = unet_block(d1, 64, name='down_block2_')\n",
    "  d2 = tfkl.MaxPooling2D()(down_block_2)\n",
    "\n",
    "  # Bottleneck\n",
    "  bottleneck = unet_block(d2, 128, name='bottleneck')\n",
    "\n",
    "  # Upsampling path\n",
    "  u1 = tfkl.UpSampling2D()(bottleneck)\n",
    "  u1 = tfkl.Concatenate()([u1, down_block_2])\n",
    "  u1 = unet_block(u1, 64, name='up_block1_')\n",
    "\n",
    "  u2 = tfkl.UpSampling2D()(u1)\n",
    "  u2 = tfkl.Concatenate()([u2, down_block_1])\n",
    "  u2 = unet_block(u2, 32, name='up_block2_')\n",
    "\n",
    "  # Output Layer\n",
    "  output_layer = tfkl.Conv2D(num_classes, kernel_size=1, padding='same', activation=\"softmax\", name='output_layer')(u2)\n",
    "\n",
    "  model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='UNet')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ATTENTION_UW_NET(img_size: tuple[int, int, int], num_classes):\n",
    "    def attention_block(x, g, inter_channel):\n",
    "        # theta_x (bs, h, w, inter_channel)\n",
    "        theta_x = tfkl.Conv2D(inter_channel, [1, 1], strides=[1, 1])(x)\n",
    "        \n",
    "        # phi_g (bs, h, w, inter_channel)\n",
    "        phi_g = tfkl.Conv2D(inter_channel, [1, 1], strides=[1, 1])(g)\n",
    "        \n",
    "        # f (bs, h, w, 1)\n",
    "        f = tfkl.Activation('relu')(tfkl.Add()([theta_x, phi_g]))\n",
    "        psi_f = tfkl.Conv2D(1, [1, 1], strides=[1, 1])(f)\n",
    "        \n",
    "        # sigmoid_psi_f (bs, h, w, 1)\n",
    "        sigmoid_psi_f = tfkl.Activation('sigmoid')(psi_f)\n",
    "        \n",
    "        # rate (bs, h, w, 1)\n",
    "        rate = tfkl.multiply([x, sigmoid_psi_f])\n",
    "        \n",
    "        return rate\n",
    "    \n",
    "    # Input\n",
    "    inputs = tfkl.Input(shape=img_size)\n",
    "    \n",
    "    # Encoder Path\n",
    "    # Block 1\n",
    "    conv1 = tfkl.Conv2D(64, 3, padding='same')(inputs)\n",
    "    conv1 = tfkl.BatchNormalization()(conv1)\n",
    "    conv1 = tfkl.Activation('relu')(conv1)\n",
    "    conv1 = tfkl.Conv2D(64, 3, padding='same')(conv1)\n",
    "    conv1 = tfkl.BatchNormalization()(conv1)\n",
    "    conv1 = tfkl.Activation('relu')(conv1)\n",
    "    pool1 = tfkl.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    # Block 2\n",
    "    conv2 = tfkl.Conv2D(128, 3, padding='same')(pool1)\n",
    "    conv2 = tfkl.BatchNormalization()(conv2)\n",
    "    conv2 = tfkl.Activation('relu')(conv2)\n",
    "    conv2 = tfkl.Conv2D(128, 3, padding='same')(conv2)\n",
    "    conv2 = tfkl.BatchNormalization()(conv2)\n",
    "    conv2 = tfkl.Activation('relu')(conv2)\n",
    "    pool2 = tfkl.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    # Block 3\n",
    "    conv3 = tfkl.Conv2D(256, 3, padding='same')(pool2)\n",
    "    conv3 = tfkl.BatchNormalization()(conv3)\n",
    "    conv3 = tfkl.Activation('relu')(conv3)\n",
    "    conv3 = tfkl.Conv2D(256, 3, padding='same')(conv3)\n",
    "    conv3 = tfkl.BatchNormalization()(conv3)\n",
    "    conv3 = tfkl.Activation('relu')(conv3)\n",
    "    pool3 = tfkl.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    # Block 4\n",
    "    conv4 = tfkl.Conv2D(512, 3, padding='same')(pool3)\n",
    "    conv4 = tfkl.BatchNormalization()(conv4)\n",
    "    conv4 = tfkl.Activation('relu')(conv4)\n",
    "    conv4 = tfkl.Conv2D(512, 3, padding='same')(conv4)\n",
    "    conv4 = tfkl.BatchNormalization()(conv4)\n",
    "    conv4 = tfkl.Activation('relu')(conv4)\n",
    "    pool4 = tfkl.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    # Bridge\n",
    "    conv5 = tfkl.Conv2D(1024, 3, padding='same')(pool4)\n",
    "    conv5 = tfkl.BatchNormalization()(conv5)\n",
    "    conv5 = tfkl.Activation('relu')(conv5)\n",
    "    conv5 = tfkl.Conv2D(1024, 3, padding='same')(conv5)\n",
    "    conv5 = tfkl.BatchNormalization()(conv5)\n",
    "    conv5 = tfkl.Activation('relu')(conv5)\n",
    "    \n",
    "    # Decoder Path with Attention\n",
    "    # Block 6\n",
    "    up6 = tfkl.Conv2D(512, 2, padding='same')(tfkl.UpSampling2D(size=(2, 2))(conv5))\n",
    "    up6 = tfkl.BatchNormalization()(up6)\n",
    "    up6 = tfkl.Activation('relu')(up6)\n",
    "    \n",
    "    att6 = attention_block(conv4, up6, inter_channel=256)\n",
    "    merge6 = tfkl.concatenate([att6, up6], axis=3)\n",
    "    \n",
    "    conv6 = tfkl.Conv2D(512, 3, padding='same')(merge6)\n",
    "    conv6 = tfkl.BatchNormalization()(conv6)\n",
    "    conv6 = tfkl.Activation('relu')(conv6)\n",
    "    conv6 = tfkl.Conv2D(512, 3, padding='same')(conv6)\n",
    "    conv6 = tfkl.BatchNormalization()(conv6)\n",
    "    conv6 = tfkl.Activation('relu')(conv6)\n",
    "    \n",
    "    # Block 7\n",
    "    up7 = tfkl.Conv2D(256, 2, padding='same')(tfkl.UpSampling2D(size=(2, 2))(conv6))\n",
    "    up7 = tfkl.BatchNormalization()(up7)\n",
    "    up7 = tfkl.Activation('relu')(up7)\n",
    "    \n",
    "    att7 = attention_block(conv3, up7, inter_channel=128)\n",
    "    merge7 = tfkl.concatenate([att7, up7], axis=3)\n",
    "    \n",
    "    conv7 = tfkl.Conv2D(256, 3, padding='same')(merge7)\n",
    "    conv7 = tfkl.BatchNormalization()(conv7)\n",
    "    conv7 = tfkl.Activation('relu')(conv7)\n",
    "    conv7 = tfkl.Conv2D(256, 3, padding='same')(conv7)\n",
    "    conv7 = tfkl.BatchNormalization()(conv7)\n",
    "    conv7 = tfkl.Activation('relu')(conv7)\n",
    "    \n",
    "    # Block 8\n",
    "    up8 = tfkl.Conv2D(128, 2, padding='same')(tfkl.UpSampling2D(size=(2, 2))(conv7))\n",
    "    up8 = tfkl.BatchNormalization()(up8)\n",
    "    up8 = tfkl.Activation('relu')(up8)\n",
    "    \n",
    "    att8 = attention_block(conv2, up8, inter_channel=64)\n",
    "    merge8 = tfkl.concatenate([att8, up8], axis=3)\n",
    "    \n",
    "    conv8 = tfkl.Conv2D(128, 3, padding='same')(merge8)\n",
    "    conv8 = tfkl.BatchNormalization()(conv8)\n",
    "    conv8 = tfkl.Activation('relu')(conv8)\n",
    "    conv8 = tfkl.Conv2D(128, 3, padding='same')(conv8)\n",
    "    conv8 = tfkl.BatchNormalization()(conv8)\n",
    "    conv8 = tfkl.Activation('relu')(conv8)\n",
    "    \n",
    "    # Block 9\n",
    "    up9 = tfkl.Conv2D(64, 2, padding='same')(tfkl.UpSampling2D(size=(2, 2))(conv8))\n",
    "    up9 = tfkl.BatchNormalization()(up9)\n",
    "    up9 = tfkl.Activation('relu')(up9)\n",
    "    \n",
    "    att9 = attention_block(conv1, up9, inter_channel=32)\n",
    "    merge9 = tfkl.concatenate([att9, up9], axis=3)\n",
    "    \n",
    "    conv9 = tfkl.Conv2D(64, 3, padding='same')(merge9)\n",
    "    conv9 = tfkl.BatchNormalization()(conv9)\n",
    "    conv9 = tfkl.Activation('relu')(conv9)\n",
    "    conv9 = tfkl.Conv2D(64, 3, padding='same')(conv9)\n",
    "    conv9 = tfkl.BatchNormalization()(conv9)\n",
    "    conv9 = tfkl.Activation('relu')(conv9)\n",
    "    \n",
    "    # Output\n",
    "    outputs = tfkl.Conv2D(num_classes, 1, activation='softmax')(conv9)\n",
    "    \n",
    "    model = tfk.Model(inputs=inputs, outputs=outputs, name='AttentionUWNet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ASPP_model(img_size: tuple[int, int, int], num_classes: int):\n",
    "    \n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "    regularizer = tf.keras.regularizers.l2(1e-4)\n",
    "\n",
    "    inputs = tfkl.Input(shape=img_size)\n",
    "\n",
    "    def conv_block(x, filters, kernel_size=(3, 3), activation=\"relu\", batch_norm=True, dropout_rate=0.2):\n",
    "        x = tfkl.Conv2D(\n",
    "            filters,\n",
    "            kernel_size,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=initializer,\n",
    "            kernel_regularizer=regularizer,\n",
    "        )(x)\n",
    "        if batch_norm:\n",
    "            x = tfkl.BatchNormalization()(x)\n",
    "        x = tfkl.Activation(activation)(x)\n",
    "        if dropout_rate > 0:\n",
    "            x = tfkl.SpatialDropout2D(dropout_rate)(x)\n",
    "        return x\n",
    "\n",
    "    def encoder_block(x, filters, dropout_rate=0.2):\n",
    "        x = conv_block(x, filters, dropout_rate=dropout_rate)\n",
    "        x = conv_block(x, filters, dropout_rate=dropout_rate)\n",
    "        p = tfkl.MaxPooling2D(2)(x)\n",
    "        return x, p\n",
    "\n",
    "    def atrous_spatial_pyramid_pooling(x, dropout_rate=0.3):\n",
    "        dims = x.shape[1:3]\n",
    "        pool = tfkl.GlobalAveragePooling2D()(x)\n",
    "        pool = tfkl.Reshape((1, 1, x.shape[-1]))(pool)\n",
    "        pool = tfkl.Conv2D(\n",
    "            256, \n",
    "            1, \n",
    "            padding=\"same\", \n",
    "            kernel_initializer=initializer, \n",
    "            kernel_regularizer=regularizer,\n",
    "        )(pool)\n",
    "        pool = tfkl.UpSampling2D(size=dims, interpolation=\"bilinear\")(pool)\n",
    "        pool = tfkl.SpatialDropout2D(dropout_rate)(pool)\n",
    "\n",
    "        conv_1x1 = tfkl.Conv2D(\n",
    "            256,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=initializer,\n",
    "            kernel_regularizer=regularizer,\n",
    "        )(x)\n",
    "        atrous_6 = tfkl.Conv2D(\n",
    "            256,\n",
    "            3,\n",
    "            dilation_rate=6,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=initializer,\n",
    "            kernel_regularizer=regularizer,\n",
    "        )(x)\n",
    "        atrous_12 = tfkl.Conv2D(\n",
    "            256,\n",
    "            3,\n",
    "            dilation_rate=12,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=initializer,\n",
    "            kernel_regularizer=regularizer,\n",
    "        )(x)\n",
    "        atrous_18 = tfkl.Conv2D(\n",
    "            256,\n",
    "            3,\n",
    "            dilation_rate=18,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=initializer,\n",
    "            kernel_regularizer=regularizer,\n",
    "        )(x)\n",
    "\n",
    "        x = tfkl.Concatenate()([pool, conv_1x1, atrous_6, atrous_12, atrous_18])\n",
    "        x = tfkl.Conv2D(\n",
    "            256,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=initializer,\n",
    "            kernel_regularizer=regularizer,\n",
    "        )(x)\n",
    "        x = tfkl.SpatialDropout2D(dropout_rate)(x)\n",
    "        return x\n",
    "\n",
    "    def decoder_block(x, skip, filters, dropout_rate=0.2):\n",
    "        x = tfkl.Conv2DTranspose(\n",
    "            filters,\n",
    "            2,\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=initializer,\n",
    "            kernel_regularizer=regularizer,\n",
    "        )(x)\n",
    "        x = tfkl.Concatenate()([x, skip])\n",
    "        x = conv_block(x, filters, dropout_rate=dropout_rate)\n",
    "        return x\n",
    "\n",
    "    # Encoder\n",
    "    filters = [64, 128, 256, 512]\n",
    "    skips = []\n",
    "    x = inputs\n",
    "    for f in filters:\n",
    "        skip, x = encoder_block(x, f, dropout_rate=0.2)\n",
    "        skips.append(skip)\n",
    "\n",
    "    # Bottleneck with ASPP\n",
    "    x = conv_block(x, 1024, dropout_rate=0.3)\n",
    "    x = atrous_spatial_pyramid_pooling(x, dropout_rate=0.3)\n",
    "\n",
    "    # Decoder\n",
    "    skips = skips[::-1]\n",
    "    decoder_filters = [512, 256, 128, 64]\n",
    "    for skip, f in zip(skips, decoder_filters):\n",
    "        x = decoder_block(x, skip, f, dropout_rate=0.2)\n",
    "\n",
    "    # Final convolutional layer\n",
    "    outputs = tfkl.Conv2D(\n",
    "        num_classes, \n",
    "        1, \n",
    "        activation=\"softmax\", \n",
    "        kernel_initializer=initializer, \n",
    "        kernel_regularizer=regularizer,\n",
    "    )(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_RockSeg(img_size: tuple[int, int, int], num_classes: int):\n",
    "    \"\"\"\n",
    "    Builds the RockSeg model, adjusted for input image size 64x128.\n",
    "\n",
    "    Parameters:\n",
    "        img_size (tuple): Input image dimensions (height, width, channels).\n",
    "        num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: RockSeg model instance.\n",
    "    \"\"\"\n",
    "\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "    regularizer = tf.keras.regularizers.l2(1e-4)  # L2 regularization with strength 1e-4\n",
    "\n",
    "    def resnet_block(input_tensor, filters, kernel_size=3, activation='relu', stack=2, name=''):\n",
    "        x = input_tensor\n",
    "        for i in range(stack):\n",
    "            x = tfkl.Conv2D(filters, kernel_size=kernel_size, padding='same', kernel_initializer=initializer,kernel_regularizer=regularizer, name=name + f'conv{i + 1}')(x)\n",
    "            x = tfkl.BatchNormalization(name=name + f'bn{i + 1}')(x)\n",
    "            x = tfkl.Activation(activation, name=name + f'activation{i + 1}')(x)\n",
    "        return x\n",
    "\n",
    "    def transformer_block(input_tensor, embed_dim, num_heads, name=''):\n",
    "        x = tfkl.Conv2D(filters=256, kernel_size=(1, 1), padding='same', kernel_initializer=initializer,kernel_regularizer=regularizer, name=name + 'transformer_11')(input_tensor)\n",
    "        x = tfkl.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\", name=name + 'avg_pool')(x)\n",
    "        x = tf.keras.layers.LayerNormalization(name=name + 'ln')(x)\n",
    "        attention_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, name=name + 'mha')(x, x)\n",
    "        x = tf.keras.layers.Add(name=name + 'skip1')([x, attention_output])\n",
    "        feed_forward = tfkl.Dense(embed_dim, activation='relu', kernel_initializer=initializer,kernel_regularizer=regularizer, name=name + 'dense')(x)\n",
    "        x = tf.keras.layers.Add(name=name + 'skip2')([x, feed_forward])\n",
    "        return x\n",
    "\n",
    "    def multiscale_feature_fusion(feature_maps, name=''):\n",
    "        base_channels = feature_maps[len(feature_maps) // 2].shape[-1]\n",
    "        consistent_features = [\n",
    "            tfkl.Conv2D(base_channels, kernel_size=(1, 1), padding='same', kernel_initializer=initializer,kernel_regularizer=regularizer, name=name + f'conv_{i}')(fm) if fm.shape[-1] != base_channels else fm\n",
    "            for i, fm in enumerate(feature_maps)\n",
    "        ]\n",
    "        base_height, base_width = consistent_features[len(consistent_features) // 2].shape[1:3]\n",
    "        resized_features = [\n",
    "            tfkl.UpSampling2D(size=(base_height // fm.shape[1], base_width // fm.shape[2]), interpolation='bilinear', name=name + f'up_{i}')(fm)\n",
    "            if fm.shape[1] < base_height else\n",
    "            tfkl.MaxPooling2D(pool_size=(fm.shape[1] // base_height, fm.shape[2] // base_width), name=name + f'pool_{i}')(fm)\n",
    "            for i, fm in enumerate(consistent_features)\n",
    "        ]\n",
    "        fused = tfkl.Concatenate(name=name + 'concat')(resized_features)\n",
    "        return tfkl.Conv2D(base_channels, kernel_size=1, padding='same', activation='relu', kernel_initializer=initializer,kernel_regularizer=regularizer, name=name + 'conv_fused')(fused)\n",
    "\n",
    "    input_layer = tfkl.Input(shape=img_size, name='input_layer')\n",
    "\n",
    "    conv1 = tfkl.Conv2D(filters=64, kernel_size=(4, 4), strides=(2, 2), padding='same', kernel_initializer=initializer,kernel_regularizer=regularizer, name='conv1')(input_layer)\n",
    "    conv1_upsampled = tfkl.UpSampling2D(size=(2, 2), interpolation='bilinear', name='conv1_upsampled')(conv1)\n",
    "    maxpool1 = tfkl.MaxPooling2D(pool_size=(2, 2), name='pool1')(conv1)\n",
    "\n",
    "    resnet1 = resnet_block(maxpool1, filters=64, stack=2, name='resnet1_')\n",
    "    resnet2 = resnet_block(resnet1, filters=128, stack=2, name='resnet2_')\n",
    "\n",
    "    transformer = transformer_block(resnet2, embed_dim=256, num_heads=4, name='transformer_')\n",
    "\n",
    "    bottleneck = tfkl.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', kernel_initializer=initializer, kernel_regularizer=regularizer, name='bottleneck')(transformer)\n",
    "\n",
    "    msf1 = multiscale_feature_fusion([resnet1, resnet2, bottleneck], name='msf1_')\n",
    "    msf1_upsampled = tfkl.UpSampling2D(size=(2, 2), interpolation='bilinear', name='msf1_upsample')(msf1)\n",
    "\n",
    "    resnet1_upsampled = tfkl.UpSampling2D(size=(2, 2), interpolation='bilinear', name='resnet1_upsample')(resnet1)\n",
    "\n",
    "    concat1 = tfkl.Concatenate(name='concat1')([msf1_upsampled, resnet1_upsampled])\n",
    "    decoder1 = tfkl.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', kernel_initializer=initializer, kernel_regularizer=regularizer, name='decoder1')(concat1)\n",
    "\n",
    "    upsample2 = tfkl.UpSampling2D(size=(2, 2), interpolation='bilinear', name='upsample2')(decoder1)\n",
    "\n",
    "    concat2 = tfkl.Concatenate(name='concat2')([upsample2, conv1_upsampled])\n",
    "    decoder2 = tfkl.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', kernel_initializer=initializer,kernel_regularizer=regularizer, name='decoder2')(concat2)\n",
    "\n",
    "    upsample3 = tfkl.UpSampling2D(size=(1, 1), interpolation='bilinear', name='upsample3')(decoder2)\n",
    "\n",
    "    output_layer = tfkl.Conv2D(num_classes, kernel_size=1, padding='same', activation=\"softmax\", kernel_initializer=initializer, name='output_layer')(upsample3)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='RockSeg')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "\t'U_NET': build_U_NET,\n",
    "\t'U_NET_XCEPTION': build_U_NET_XCEPTION,\n",
    "  'UWNet': build_ATTENTION_UW_NET,\n",
    "  'ASPP' : build_ASPP_model,\n",
    "  'ROCKSEG' : build_RockSeg\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T21:00:15.925010Z",
     "iopub.status.busy": "2024-11-21T21:00:15.924678Z",
     "iopub.status.idle": "2024-11-21T21:00:15.939252Z",
     "shell.execute_reply": "2024-11-21T21:00:15.938433Z",
     "shell.execute_reply.started": "2024-11-21T21:00:15.924970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_callbacks():\n",
    "\treturn [i for i in model_fit_callbacks.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T21:00:15.940614Z",
     "iopub.status.busy": "2024-11-21T21:00:15.940360Z",
     "iopub.status.idle": "2024-11-21T21:00:15.949708Z",
     "shell.execute_reply": "2024-11-21T21:00:15.948895Z",
     "shell.execute_reply.started": "2024-11-21T21:00:15.940588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, data_loader=None, validation_data_loader=None):\n",
    "  assert(data_loader is not None)\n",
    "  assert(validation_data_loader is not None)\n",
    "  fit_history = model.fit(\n",
    "        data_loader,\n",
    "\t      epochs=epochs,\n",
    "        validation_data=validation_data_loader,\n",
    "\t      callbacks=get_callbacks()\n",
    "\t    ).history\n",
    "  return fit_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T21:00:15.964995Z",
     "iopub.status.busy": "2024-11-21T21:00:15.964769Z",
     "iopub.status.idle": "2024-11-21T21:00:15.978997Z",
     "shell.execute_reply": "2024-11-21T21:00:15.978372Z",
     "shell.execute_reply.started": "2024-11-21T21:00:15.964972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Taken from https://github.com/SeanSdahl/RangerOptimizerTensorflow/blob/master/module.py\n",
    "def build_ranger(lr=1e-3, weight_decay=0.0):\n",
    "  try:\n",
    "    import tensorflow_addons as tfa\n",
    "  except:\n",
    "    raise Exception(\"You have to install tensorflow_addons package for Ranger. Please note that this package is available up to tensorflow==2.14\")\n",
    "  def ranger(sync_period=6,\n",
    "           slow_step_size=0.5,\n",
    "           learning_rate=lr,\n",
    "           beta_1=0.9,\n",
    "           beta_2=0.999,\n",
    "           epsilon=1e-7,\n",
    "           weight_decay=weight_decay,\n",
    "           amsgrad=False,\n",
    "           sma_threshold=5.0,\n",
    "           total_steps=0,\n",
    "           warmup_proportion=0.1,\n",
    "           min_lr=0.,\n",
    "           name=\"Ranger\"):\n",
    "    inner = tfa.optimizers.RectifiedAdam(learning_rate, beta_1, beta_2, epsilon, weight_decay, amsgrad, sma_threshold, total_steps, warmup_proportion, min_lr, name)\n",
    "    optim = tfa.optimizers.Lookahead(inner, sync_period, slow_step_size, name)\n",
    "    return optim\n",
    "  return ranger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T21:00:15.980359Z",
     "iopub.status.busy": "2024-11-21T21:00:15.980111Z",
     "iopub.status.idle": "2024-11-21T21:00:15.995129Z",
     "shell.execute_reply": "2024-11-21T21:00:15.994358Z",
     "shell.execute_reply.started": "2024-11-21T21:00:15.980335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(is_fine_tuning = False, use_decay_fine_tuning = False, **kwargs):\n",
    "\tdecay = opt_exp_decay_rate\n",
    "\tif is_fine_tuning and not use_decay_fine_tuning:\n",
    "\t\tdecay = None\n",
    "\n",
    "\topt = opt_name if not is_fine_tuning else fine_tuning_opt_name\n",
    "\n",
    "\tif opt == \"SGD\":\n",
    "\t\toptimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9 if 'momentum' not in kwargs else kwargs['momentum'])\n",
    "\t\tif decay is not None:\n",
    "\t\t\tlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "\t\t\t\t\tinitial_learning_rate=fine_tuning_lr if is_fine_tuning else lr,\n",
    "\t\t\t\t\tdecay_steps=opt_decay_epoch_delta * (X_train.shape[0] // batch_size),  # Decay every 7 epochs\n",
    "\t\t\t\t\tdecay_rate=opt_exp_decay_rate,\n",
    "\t\t\t\t\tstaircase=True\n",
    "\t\t\t)\n",
    "\t\t\toptimizer.learning_rate = lr_schedule\n",
    "\t\t\tprint(f'\\n\\n{\"Finetuning: \" if is_fine_tuning else \"NotFinetuning: \"}using {opt} optimizer with exp decay {decay} (momentum = {optimizer.momentum})\\n\\n')\n",
    "\t\t\treturn optimizer\n",
    "\t\telse:\n",
    "\t\t\toptimizer.learning_rate = fine_tuning_lr if is_fine_tuning else lr\n",
    "\t\t\tprint(f'\\n\\n{\"Finetuning: \" if is_fine_tuning else \"NotFinetuning: \"}using {opt} optimizer (momentum = {optimizer.momentum})\\n\\n')\n",
    "\t\t\treturn optimizer\n",
    "\n",
    "\telif opt == \"Adam\":\n",
    "\t\tif 'weight_decay' in kwargs:\n",
    "\t\t\toptimizer = tf.keras.optimizers.Adam(weight_decay=kwargs['weight_decay'])\n",
    "\t\telse:\n",
    "\t\t\toptimizer = tf.keras.optimizers.Adam()\n",
    "\t\tif decay is not None:\n",
    "\t\t\tlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "\t\t\t\t\tinitial_learning_rate=fine_tuning_lr if is_fine_tuning else lr,\n",
    "\t\t\t\t\tdecay_steps=opt_decay_epoch_delta * (X_train.shape[0] // batch_size),  # Decay every 7 epochs\n",
    "\t\t\t\t\tdecay_rate=opt_exp_decay_rate,\n",
    "\t\t\t\t\tstaircase=True\n",
    "\t\t\t)\n",
    "\t\t\toptimizer.learning_rate = lr_schedule\n",
    "\t\t\tprint(f'\\n\\n{\"Finetuning: \" if is_fine_tuning else \"NotFinetuning: \"}using {opt} optimizer with exp decay of {decay} weight decay = {optimizer.weight_decay}\\n\\n')\n",
    "\t\t\treturn optimizer\n",
    "\t\telse:\n",
    "\t\t\toptimizer.learning_rate = fine_tuning_lr if is_fine_tuning else lr\n",
    "\t\t\tprint(f'\\n\\n{\"Finetuning: \" if is_fine_tuning else \"NotFinetuning: \"}using {opt} optimizer (weight decay = {optimizer.weight_decay})\\n\\n')\n",
    "\t\t\treturn optimizer\n",
    "\n",
    "\telif opt == \"AdamW\":\n",
    "\t\tif 'weight_decay' in kwargs:\n",
    "\t\t\toptimizer = tf.keras.optimizers.AdamW(weight_decay=kwargs['weight_decay'])\n",
    "\t\telse:\n",
    "\t\t\toptimizer = tf.keras.optimizers.AdamW()\n",
    "\t\tif decay is not None:\n",
    "\t\t\tlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "\t\t\t\t\tinitial_learning_rate=fine_tuning_lr if is_fine_tuning else lr,\n",
    "\t\t\t\t\tdecay_steps=opt_decay_epoch_delta * (X_train.shape[0] // batch_size),  # Decay every 7 epochs\n",
    "\t\t\t\t\tdecay_rate=opt_exp_decay_rate,\n",
    "\t\t\t\t\tstaircase=True\n",
    "\t\t\t)\n",
    "\t\t\toptimizer.learning_rate = lr_schedule\n",
    "\t\t\tprint(f'\\n\\n{\"Finetuning: \" if is_fine_tuning else \"NotFinetuning: \"}using {opt} optimizer with exp decay of {decay} weight decay = {optimizer.weight_decay}\\n\\n')\n",
    "\t\t\treturn optimizer\n",
    "\t\telse:\n",
    "\t\t\toptimizer.learning_rate = fine_tuning_lr if is_fine_tuning else lr\n",
    "\t\t\tprint(f'\\n\\n{\"Finetuning: \" if is_fine_tuning else \"NotFinetuning: \"}using {opt} optimizer (weight decay = {optimizer.weight_decay})\\n\\n')\n",
    "\t\t\treturn optimizer\n",
    "\n",
    "\telif opt == \"Lion\":\n",
    "\t\tif 'weight_decay' in kwargs:\n",
    "\t\t\toptimizer = tf.keras.optimizers.Lion(weight_decay=kwargs['weight_decay'])\n",
    "\t\telse:\n",
    "\t\t\toptimizer = tf.keras.optimizers.Lion()\n",
    "\t\tif decay is not None:\n",
    "\t\t\tlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "\t\t\t\t\tinitial_learning_rate=fine_tuning_lr if is_fine_tuning else lr,\n",
    "\t\t\t\t\tdecay_steps=opt_decay_epoch_delta * (X_train.shape[0] // batch_size),  # Decay every 7 epochs\n",
    "\t\t\t\t\tdecay_rate=opt_exp_decay_rate,\n",
    "\t\t\t\t\tstaircase=True\n",
    "\t\t\t)\n",
    "\t\t\toptimizer.learning_rate = lr_schedule\n",
    "\t\t\tprint(f'\\n\\n{\"Finetuning: \" if is_fine_tuning else \"NotFinetuning: \"}using {opt} optimizer with exp decay of {decay} weight decay = {optimizer.weight_decay}\\n\\n')\n",
    "\t\t\treturn optimizer\n",
    "\t\telse:\n",
    "\t\t\toptimizer.learning_rate = fine_tuning_lr if is_fine_tuning else lr\n",
    "\t\t\tprint(f'\\n\\n{\"Finetuning: \" if is_fine_tuning else \"NotFinetuning: \"}using {opt} optimizer (weight decay = {optimizer.weight_decay})\\n\\n')\n",
    "\t\t\treturn optimizer\n",
    "\telif opt == \"Ranger\":\n",
    "\t\toptimizer = build_ranger(lr=lr if not is_fine_tuning else fine_tuning_lr, weight_decay=0.0 if 'weight_decay' not in kwargs else kwargs['weight_decay'])\n",
    "\t\tif decay is not None:\n",
    "\t\t\traise RuntimeError(\"Not supported\")\n",
    "\t\telse:\n",
    "\t\t\toptimizer.learning_rate = fine_tuning_lr if is_fine_tuning else lr\n",
    "\t\t\tprint(f'\\n\\n{\"Finetuning: \" if is_fine_tuning else \"NotFinetuning: \"}using {opt} optimizer\\n\\n')\n",
    "\t\t\treturn optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T21:00:15.996454Z",
     "iopub.status.busy": "2024-11-21T21:00:15.996146Z",
     "iopub.status.idle": "2024-11-21T21:00:16.006383Z",
     "shell.execute_reply": "2024-11-21T21:00:16.005722Z",
     "shell.execute_reply.started": "2024-11-21T21:00:15.996418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display_model(model):\n",
    "\t# Display a summary of the model architecture\n",
    "\tmodel.summary(expand_nested=True)\n",
    "\n",
    "\t# Display model architecture with layer shapes and trainable parameters\n",
    "\ttfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üç£ Define and display model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom Mean Intersection Over Union metric: the competition excludes the background class\n",
    "class MeanIntersectionOverUnion(tf.keras.metrics.MeanIoU):\n",
    "  def __init__(self, num_classes, labels_to_exclude=None, name=\"mean_iou\", dtype=None):\n",
    "    super(MeanIntersectionOverUnion, self).__init__(num_classes=num_classes, name=name, dtype=dtype)\n",
    "    if labels_to_exclude is None:\n",
    "      labels_to_exclude = [0]  # Default to excluding label 0\n",
    "    self.labels_to_exclude = labels_to_exclude\n",
    "\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    # Convert predictions to class labels\n",
    "    y_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "\n",
    "    # Flatten the tensors\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "\n",
    "    # Apply mask to exclude specified labels\n",
    "    for label in self.labels_to_exclude:\n",
    "      mask = tf.not_equal(y_true, label)\n",
    "      y_true = tf.boolean_mask(y_true, mask)\n",
    "      y_pred = tf.boolean_mask(y_pred, mask)\n",
    "\n",
    "    # Update the state\n",
    "    return super().update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_dict[model_name](IMG_SIZE + (1,), NUM_CLASSES)\n",
    "\n",
    "model.compile(loss=loss_fn, optimizer=get_optimizer(is_fine_tuning=False), metrics=['accuracy', MeanIntersectionOverUnion(num_classes=NUM_CLASSES, labels_to_exclude=[0])])\n",
    "display_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßóüèª‚Äç‚ôÇÔ∏è Train and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T21:00:16.008010Z",
     "iopub.status.busy": "2024-11-21T21:00:16.007418Z",
     "iopub.status.idle": "2024-11-22T01:38:32.003037Z",
     "shell.execute_reply": "2024-11-22T01:38:32.001978Z",
     "shell.execute_reply.started": "2024-11-21T21:00:16.007972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fit the initial model\n",
    "print('\\n\\nFitting model\\n\\n')\n",
    "fit_history = fit_model(model, data_loader=get_dataset(X_train, y_train, batch_size=batch_size, augmentations=apply_augmentation, concat_and_shuffle_aug_with_no_aug=True), validation_data_loader=get_dataset(X_val, y_val, batch_size=batch_size))\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_meanIoU = round(max(fit_history['val_mean_iou'])* 100, 2)\n",
    "print(f'Final validation Mean Intersection Over Union: {final_val_meanIoU}%')\n",
    "\n",
    "# Save intermediate model\n",
    "model_filename = f'{model_name}-{str(final_val_meanIoU)}-{datetime.now().strftime(\"%y%m%d_%H%M\")}.keras'\n",
    "model.save(model_filename)\n",
    "\n",
    "# Free memory by deleting the model instance\n",
    "if FREE_MODEL:\n",
    "  del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T01:38:32.004572Z",
     "iopub.status.busy": "2024-11-22T01:38:32.004292Z",
     "iopub.status.idle": "2024-11-22T01:38:32.539916Z",
     "shell.execute_reply": "2024-11-22T01:38:32.538708Z",
     "shell.execute_reply.started": "2024-11-22T01:38:32.004546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_trainig(fit):\n",
    "  # Plot and display training and validation loss\n",
    "  plt.figure(figsize=(18, 3))\n",
    "  plt.plot(fit['loss'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\n",
    "  plt.plot(fit['val_loss'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\n",
    "  plt.title('Cross Entropy')\n",
    "  plt.legend()\n",
    "  plt.grid(alpha=0.3)\n",
    "  plt.show()\n",
    "\n",
    "  # Plot and display training and validation accuracy\n",
    "  plt.figure(figsize=(18, 3))\n",
    "  plt.plot(fit['accuracy'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\n",
    "  plt.plot(fit['val_accuracy'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\n",
    "  plt.title('Accuracy')\n",
    "  plt.legend()\n",
    "  plt.grid(alpha=0.3)\n",
    "  plt.show()\n",
    "\n",
    "  # Plot and display training and validation mean IoU\n",
    "  plt.figure(figsize=(18, 3))\n",
    "  plt.plot(fit['mean_iou'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\n",
    "  plt.plot(fit['val_mean_iou'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\n",
    "  plt.title('Mean Intersection over Union')\n",
    "  plt.legend()\n",
    "  plt.grid(alpha=0.3)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trainig(fit_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úçüèø Make prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = get_dataset(X_test, y_test, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UNet model without compiling\n",
    "model = tfk.models.load_model('UNet_59.26.keras', compile=False)\n",
    "\n",
    "# Compile the model with specified loss, optimizer, and metrics\n",
    "model.compile(\n",
    "    loss=loss_fn,\n",
    "    optimizer=get_optimizer(),\n",
    "    metrics=[\"accuracy\", MeanIntersectionOverUnion(num_classes=NUM_CLASSES, labels_to_exclude=[0])]\n",
    ")\n",
    "\n",
    "display_model(model)\n",
    "\n",
    "# Evaluate the model on the test set and print the results\n",
    "test_loss, test_accuracy, test_mean_iou = model.evaluate(test_dataset, verbose=1)\n",
    "print(f'Test Accuracy: {round(test_accuracy, 4)}')\n",
    "print(f'Test Mean Intersection over Union: {round(test_mean_iou, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segmentation_colormap(num_classes):\n",
    "  \"\"\"\n",
    "  Create a linear colormap using a predefined palette.\n",
    "  Uses 'viridis' as default because it is perceptually uniform\n",
    "  and works well for colorblindness.\n",
    "  \"\"\"\n",
    "  return plt.cm.viridis(np.linspace(0, 1, num_classes))\n",
    "\n",
    "def apply_colormap(label, colormap=None):\n",
    "  \"\"\"\n",
    "  Apply the colormap to a label.\n",
    "  \"\"\"\n",
    "  # Ensure label is 2D\n",
    "  label = np.squeeze(label)\n",
    "\n",
    "  if colormap is None:\n",
    "    num_classes = len(np.unique(label))\n",
    "    colormap = create_segmentation_colormap(num_classes)\n",
    "\n",
    "  # Apply the colormap\n",
    "  colored = colormap[label.astype(int)]\n",
    "\n",
    "  return colored\n",
    "\n",
    "def plot_triptychs(dataset, model, num_samples=1):\n",
    "  \"\"\"\n",
    "  Plot triptychs (original image, true mask, predicted mask) for samples from a tf.data.Dataset\n",
    "\n",
    "  Parameters:\n",
    "  dataset: tf.data.Dataset - The dataset containing image-label pairs\n",
    "  model: tf.keras.Model - The trained model to generate predictions\n",
    "  num_samples: int - Number of samples to plot\n",
    "  \"\"\"\n",
    "  # Take samples from the dataset\n",
    "  samples = dataset.take(num_samples)\n",
    "\n",
    "  for images, labels in samples:\n",
    "    # If we have a batch, take the first example\n",
    "    if len(images.shape) == 4:  # Batch of images\n",
    "      images = images[0:1]\n",
    "      labels = labels[0:1]\n",
    "\n",
    "    # Generate predictions\n",
    "    pred = model.predict(images, verbose=0)\n",
    "    pred = tf.math.argmax(pred, axis=-1)\n",
    "\n",
    "    # Create colormap based on number of classes in labels\n",
    "    labels_np = labels.numpy()\n",
    "    num_classes = len(np.unique(labels_np))\n",
    "    colormap = create_segmentation_colormap(num_classes)\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 4))\n",
    "\n",
    "    # Plot original image\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].imshow(images[0])\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Plot original mask\n",
    "    axes[1].set_title(\"Original Mask\")\n",
    "    colored_label = apply_colormap(labels[0], colormap)\n",
    "    axes[1].imshow(colored_label)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Plot predicted mask\n",
    "    axes[2].set_title(\"Predicted Mask\")\n",
    "    colored_pred = apply_colormap(pred[0], colormap)\n",
    "    axes[2].imshow(colored_pred)\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_triptychs(test_dataset, model, num_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## üé∞ Make prediction on competition test set and create csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are not loading the model but using the python env model as there is a current error on the `MeanIntersectionOverUnion` class which is not serializable making the model not loadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(hidden_X_test.shape)\n",
    "preds = model.predict(hidden_X_test)\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "\n",
    "def y_to_df(y) -> pd.DataFrame:\n",
    "  \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n",
    "  n_samples = len(y)\n",
    "  y_flat = y.reshape(n_samples, -1)\n",
    "  df = pd.DataFrame(y_flat)\n",
    "  df[\"id\"] = np.arange(n_samples)\n",
    "  cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n",
    "  return df[cols]\n",
    "\n",
    "submission_filename = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M\")}.csv'\n",
    "submission_df = y_to_df(preds)\n",
    "submission_df.to_csv(submission_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPhN8z97sycURDAjAFsp+EI",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6047840,
     "sourceId": 9855285,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6047865,
     "sourceId": 9855319,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 159775,
     "modelInstanceId": 137060,
     "sourceId": 161170,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 162416,
     "modelInstanceId": 139795,
     "sourceId": 164339,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 164634,
     "modelInstanceId": 142056,
     "sourceId": 166955,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 165351,
     "modelInstanceId": 142773,
     "sourceId": 167821,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 170852,
     "modelInstanceId": 148341,
     "sourceId": 174251,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
