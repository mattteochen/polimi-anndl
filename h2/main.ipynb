{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuwVgG3Vbbka"
   },
   "source": [
    "# Artificial Neural Networks and Deep Learning\n",
    "\n",
    "---\n",
    "## Homework 2: Image segmentation of Mars' stones\n",
    "## Team: The Backpropagators\n",
    "Arianna Procaccio, Francesco Buccoliero, Kai-Xi Matteo Chen, Luca Capoferri\n",
    "\n",
    "ariii, frbuccoliero, kaiximatteoc, luke01\n",
    "\n",
    "246843, 245498, 245523, 259617\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7IqZP5Iblna"
   },
   "source": [
    "## âš™ï¸ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T20:59:48.162042Z",
     "iopub.status.busy": "2024-11-21T20:59:48.161808Z",
     "iopub.status.idle": "2024-11-21T20:59:48.172447Z",
     "shell.execute_reply": "2024-11-21T20:59:48.171556Z",
     "shell.execute_reply.started": "2024-11-21T20:59:48.162018Z"
    },
    "id": "CO6_Ft_8T56A",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âš™ï¸ Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 666\n",
    "\n",
    "train_ratio = 0.85\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.05\n",
    "\n",
    "IMG_SIZE = (64, 128)\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "running_on = \"local\" # local | colab | kaggle\n",
    "\n",
    "quick_run = True # If true skips the early plotting stuff\n",
    "\n",
    "model_name = 'ASPP' # U_NET | U_NET_XCEPTION | UWNet | ASPP | ROCKSEG | TURKEYSEG | GROUP_NORM_UNET | LIGHT4MARS\n",
    "\n",
    "# Training schedule\n",
    "training_schedule = [\n",
    "  # Second run over augmented data\n",
    "  {\n",
    "    \"augmentation\" : True,\n",
    "    \"augmentation_repetition\": 2,\n",
    "    #\"enlarge_dataset_with_custom_np_ds\": True,\n",
    "    \"include_non_augmented\": True,\n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"opt_name\": \"AdamW\", # SGD | Adam | AdamW | Lion | Ranger\n",
    "  }\n",
    "]\n",
    "\n",
    "# Exponential decay\n",
    "opt_exp_decay_rate: float | None = None \n",
    "opt_decay_epoch_delta = 7 # Number of epochs between each decay, if above None is not used\n",
    "\n",
    "USE_CLASS_WEIGHTS: bool | list[int,int,int,int,int] = False # If true will use class weights for loss function, if false will use all ones, if list will use that list\n",
    "\n",
    "loss_fn = 'combined_loss' # sparse_categorical_crossentropy | boundary_loss | dice_loss | combined_loss\n",
    "\n",
    "FREE_MODEL = False # If true the model is deleted from memory after being dumped to file\n",
    "\n",
    "model_filename_override = None # If not None will load the model from this file and perform inference\n",
    "\n",
    "DATASET_PATH_LOCAL = \"dataset.npz\"\n",
    "DATASET_PATH_COLAB = \"/content/drive/MyDrive/Colab Notebooks/dataset.npz\"\n",
    "DATASET_PATH_KAGGLE = \"/kaggle/input/dataset-h2/dataset.npz\"\n",
    "\n",
    "OUTLIER_MASK_LOCAL = \"outlier_mask.npy\"\n",
    "OUTLIER_MASK_COLAB = \"/content/drive/MyDrive/Colab Notebooks/outlier_mask.npy\"\n",
    "OUTLIER_MASK_KAGGLE = \"/kaggle/input/dataset-h2/outlier_mask.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define here the Albumentation pipeline to be used for augmentation\n",
    "\n",
    "def build_augmentation():\n",
    "  transform = A.Compose([\n",
    "          A.RandomRotate90(p=0.7),  # Random 90-degree rotation\n",
    "          A.HorizontalFlip(p=0.7),  # Horizontal flip for diverse texture representation\n",
    "          A.VerticalFlip(p=0.7),  # Vertical flip to simulate different orientations\n",
    "          A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),  # Adjust brightness and contrast\n",
    "          A.GaussianBlur(blur_limit=3, p=0.7),  # Add blur to simulate camera effects\n",
    "          A.CoarseDropout(max_holes=4, max_height=16, max_width=16, p=0.7),  # Randomly occlude parts of the image\n",
    "          A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=45, p=0.7),  # Random shifts, scales, and rotations\n",
    "          A.ElasticTransform(alpha=1, sigma=50, p=0.7),\n",
    "          A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.7),\n",
    "          A.OpticalDistortion(distort_limit=0.2, shift_limit=0.2, p=0.7),\n",
    "          A.Resize(height=IMG_SIZE[0], width=IMG_SIZE[1], p=1),  # Resize for consistent input size\n",
    "      ])\n",
    "\n",
    "  # # For Matteo, do not delete\n",
    "  # transform = A.Compose([\n",
    "  #  A.RandomRotate90(p=0.7),  # Random 90-degree rotation\n",
    "  #  A.HorizontalFlip(p=0.7),  # Horizontal flip for diverse texture representation\n",
    "  #  A.VerticalFlip(p=0.7),  # Vertical flip to simulate different orientations\n",
    "  #  A.ElasticTransform(alpha=50, sigma=50, p=0.7),\n",
    "  #  A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.7),\n",
    "  #  A.Resize(height=IMG_SIZE[0], width=IMG_SIZE[1], p=1),  # Resize for consistent input size\n",
    "  # ])\n",
    "  \n",
    "  return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom augmentation for some specific targets (e.g. images with a lot of background)\n",
    "def build_augmentation_bg():\n",
    "  transform = A.Compose([\n",
    "      A.RandomRotate90(p=0.5),  # Random 90-degree rotation\n",
    "      A.HorizontalFlip(p=0.5),  # Horizontal flip for diverse texture representation\n",
    "      A.VerticalFlip(p=0.5),  # Vertical flip to simulate different orientations\n",
    "      A.Resize(height=IMG_SIZE[0], width=IMG_SIZE[1], p=1),  # Resize for consistent input size\n",
    "    ])\n",
    "  return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading configurations based on the given settings\n",
    "assert train_ratio + validation_ratio + test_ratio == 1\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "DATASET_PATH = DATASET_PATH_LOCAL if running_on == \"local\" else DATASET_PATH_COLAB if running_on == \"colab\" else DATASET_PATH_KAGGLE\n",
    "OUTLIER_MASK = OUTLIER_MASK_LOCAL if running_on == \"local\" else OUTLIER_MASK_COLAB if running_on == \"colab\" else OUTLIER_MASK_KAGGLE\n",
    "\n",
    "data = np.load(DATASET_PATH)\n",
    "outlier_mask_template = np.load(OUTLIER_MASK) # discovered by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN_cpHlSboXV"
   },
   "source": [
    "## â³ Load, inspect and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = data[\"training_set\"]\n",
    "X_train = training_set[:, 0]\n",
    "y_train = training_set[:, 1]\n",
    "\n",
    "hidden_X_test = data[\"test_set\"]\n",
    "\n",
    "print(f\"Training X shape: {X_train.shape}\")\n",
    "print(f\"Training y shape: {y_train.shape}\")\n",
    "print(f\"Test hidden X shape: {hidden_X_test.shape}\")\n",
    "\n",
    "# Add color channel and rescale pixels between 0 and 1\n",
    "X_train = X_train[..., np.newaxis] / 255\n",
    "X_train = X_train.astype(np.float32)\n",
    "hidden_X_test = hidden_X_test[..., np.newaxis] / 255\n",
    "hidden_X_test = hidden_X_test.astype(np.float32)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Split train and validation\n",
    "validation_size = int(X_train.shape[0] * validation_ratio)\n",
    "\n",
    "indices = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X_train = X_train[indices]\n",
    "y_train = y_train[indices]\n",
    "\n",
    "# Define train and validation indices\n",
    "split_indices = [int(X_train.shape[0] * train_ratio), int(X_train.shape[0] * (train_ratio + validation_ratio))]\n",
    "\n",
    "X_train, X_val, X_test = np.split(X_train, split_indices)\n",
    "y_train, y_val, y_test = np.split(y_train, split_indices)\n",
    "\n",
    "print(\"======= BEFORE REMOVING OUTLIERS =======\")\n",
    "print(f\"Training X shape: {X_train.shape}\")\n",
    "print(f\"Training y shape: {y_train.shape}\")\n",
    "print(f\"Validation X shape: {X_val.shape}\")\n",
    "print(f\"Validation y shape: {y_val.shape}\")\n",
    "print(f\"Test X shape: {X_test.shape}\")\n",
    "print(f\"Test y shape: {y_test.shape}\")\n",
    "\n",
    "# Outliers share the mask\n",
    "train_outliers_indices = [i for i, img in enumerate(y_train) if not np.array_equal(img, outlier_mask_template)]\n",
    "val_outliers_indices = [i for i, img in enumerate(y_val) if not np.array_equal(img, outlier_mask_template)]\n",
    "test_outliers_indices = [i for i, img in enumerate(y_test) if not np.array_equal(img, outlier_mask_template)]\n",
    "print(f'Total outliers in train set: {y_train.shape[0] - len(train_outliers_indices)}')\n",
    "print(f'Total outliers in validation set: {y_val.shape[0] - len(val_outliers_indices)}')\n",
    "print(f'Total outliers in test set: {y_test.shape[0] - len(test_outliers_indices)}')\n",
    "\n",
    "# Remove outlier from train and validation set\n",
    "X_train = X_train[train_outliers_indices]\n",
    "y_train = y_train[train_outliers_indices]\n",
    "X_val = X_val[val_outliers_indices]\n",
    "y_val = y_val[val_outliers_indices]\n",
    "X_test = X_test[test_outliers_indices]\n",
    "y_test = y_test[test_outliers_indices]\n",
    "\n",
    "print(\"======= AFTER REMOVING OUTLIERS =======\")\n",
    "print(f'Updated train dataset size: {X_train.shape}')\n",
    "print(f'Updated validation dataset size: {X_val.shape}')\n",
    "print(f'Updated test dataset size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve images with a lot of label labels\n",
    "def retrieve_imgs_of_label(X, y, bg_label_min_percentage=0.9, label=0):\n",
    "  tot_pixels = IMG_SIZE[0] * IMG_SIZE[1]\n",
    "  imgs = []\n",
    "  labels = []\n",
    "  # Count pixels for each class\n",
    "  for label_image, img in zip(y, X):\n",
    "    unique, counts = np.unique(label_image, return_counts=True)\n",
    "    for u, c in zip(unique, counts):\n",
    "      if int(u) == label and c / tot_pixels >= bg_label_min_percentage:\n",
    "        imgs.append(img)\n",
    "        labels.append(label_image)\n",
    "  return np.array(imgs), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve noisy labelled images\n",
    "noisy_images = {i: () for i in range(5)}\n",
    "for k in noisy_images.keys():\n",
    "  imgs, labels = retrieve_imgs_of_label(X_train, y_train, bg_label_min_percentage=0.85, label=k)\n",
    "  noisy_images[k] = (imgs, labels)\n",
    "  print('Retrieved images:', noisy_images[k][0].shape[0], 'with at least 75% of label', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data. The number of images being displayed are rows X cols\n",
    "def plot(data, mask=None, num_images=10, rows=4, cols=8, num_cls=5, colors=None):\n",
    "  # Reshape if needed (e.g., remove channel dimension for grayscale images)\n",
    "  if data.shape[-1] == 1:  # Grayscale case\n",
    "    data = data.squeeze(axis=-1)  # Remove channel dimension\n",
    "  \n",
    "  if mask is None:\n",
    "    # Plot settings\n",
    "    _, axes = plt.subplots(rows, cols, figsize=(12, 6))  # Adjust figure size as needed\n",
    "  \n",
    "    # Display images\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "      if i < len(data):  # Check if there are enough images\n",
    "        ax.imshow(data[i], cmap='gray' if len(data[i].shape) == 2 else None)\n",
    "        ax.axis('off')  # Hide axes\n",
    "      else:\n",
    "        ax.axis('off')  # Hide any empty subplot\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "  else:\n",
    "\n",
    "    # Define custom colors for each class\n",
    "    import matplotlib.colors as mcolors\n",
    "    if num_cls == 2:\n",
    "      class_colors = [\"blue\", \"purple\"] if colors is None else colors\n",
    "      bounds = [0,0.5,1.5]\n",
    "    elif num_classes == 5:\n",
    "      class_colors = [\"purple\", \"blue\", \"green\", \"orange\", \"yellow\"] if colors is None else colors\n",
    "      bounds = [0,0.5,1.5,2.5,3.5,4.5]\n",
    "    else:\n",
    "      raise RuntimeError('Not impl')\n",
    "    cmap = mcolors.ListedColormap(class_colors)\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    # Define normalization to map class values to the color map\n",
    "    bounds = np.arange(num_cls + 1) - 0.5  # Create boundaries for each class\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    num_samples = num_images  # Number of images to display\n",
    "    if num_samples < 4:\n",
    "      num_samples = 4\n",
    "\n",
    "    # Plot settings\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(8, num_samples * 2))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "      # Original image\n",
    "      axes[i, 0].imshow(data[i], cmap=\"gray\")\n",
    "      axes[i, 0].set_title(f\"Image {i+1}\")\n",
    "      axes[i, 0].axis(\"off\")\n",
    "\n",
    "      # Corresponding mask\n",
    "      axes[i, 1].imshow(mask[i], cmap=cmap, norm=norm)  # Adjust cmap as needed\n",
    "      axes[i, 1].set_title(f\"Mask {i+1}\")\n",
    "      axes[i, 1].axis(\"off\")\n",
    "    # Add a colorbar\n",
    "    cbar = fig.colorbar(\n",
    "      plt.cm.ScalarMappable(cmap=cmap, norm=norm),\n",
    "      ax=axes[:, 1],  # Align the colorbar with the mask columns\n",
    "      orientation=\"vertical\",\n",
    "      fraction=0.02,\n",
    "      pad=0.04\n",
    "    )\n",
    "    cbar.set_ticks(np.arange(num_cls))  # Set tick locations\n",
    "    cbar.set_ticklabels([f\"Class {i}\" for i in range(num_cls)])  # Set tick labels\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not quick_run:\n",
    "  plot(X_train, rows=10, cols=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An additional check: you should not see any outlier\n",
    "if not quick_run:\n",
    "  plot(X_val, mask=y_val, num_images=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class_distribution(label_dataset, num_classes):\n",
    "  # Initialize counts for each class\n",
    "  class_counts = np.zeros(num_classes)\n",
    "\n",
    "  # Count pixels for each class\n",
    "  for label_image in label_dataset:\n",
    "      unique, counts = np.unique(label_image, return_counts=True)\n",
    "      for u, c in zip(unique, counts):\n",
    "          class_counts[u] += c\n",
    "\n",
    "  # Normalize counts (percentage)\n",
    "  total_pixels = np.sum(class_counts)\n",
    "  class_distribution = class_counts / total_pixels * 100\n",
    "\n",
    "  # Print and visualize\n",
    "  print(\"Class Distribution (% of pixels):\")\n",
    "  for i in range(num_classes):\n",
    "      print(f\"Class {i}: {class_distribution[i]:.2f}%\")\n",
    "  \n",
    "  if not quick_run:\n",
    "    # Plot class distribution\n",
    "    plt.bar(range(num_classes), class_distribution, tick_label=[f\"Class {i}\" for i in range(num_classes)])\n",
    "    plt.xlabel(\"Classes\")\n",
    "    plt.ylabel(\"Percentage of Pixels\")\n",
    "    plt.title(\"Class Distribution\")\n",
    "    plt.show()\n",
    "  \n",
    "  return class_distribution\n",
    "\n",
    "def get_class_weights(class_distribution):\n",
    "  # Convert percentage to class probabilities\n",
    "  class_probabilities = np.array(class_distribution) / 100.0\n",
    "\n",
    "  # Calculate class weights (inverse of class probability)\n",
    "  class_weights = 1.0 / class_probabilities\n",
    "\n",
    "  # Normalize weights (optional, you can skip normalization if desired)\n",
    "  max_weight = np.max(class_weights)\n",
    "  class_weights = class_weights / max_weight  # Normalize to have the maximum weight = 1\n",
    "\n",
    "  return {i:w for i,w in enumerate(class_weights)}\n",
    "\n",
    "# Check for 5 classes (class IDs: 0-4)\n",
    "class_distribution = check_class_distribution([e.astype(np.int8) for e in y_train], num_classes=num_classes)\n",
    "\n",
    "if type(USE_CLASS_WEIGHTS) == bool:\n",
    "  if USE_CLASS_WEIGHTS:\n",
    "    class_weights = get_class_weights(class_distribution)\n",
    "  else:\n",
    "    class_weights = {i: 1.0/num_classes for i in range(num_classes)}\n",
    "else:\n",
    "  class_weights = {i: w for i, w in enumerate(USE_CLASS_WEIGHTS)}\n",
    "\n",
    "print('Class weights:', class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `concat_and_shuffle_aug_with_no_aug` will double the X_train size\n",
    "# `remove_bg` will set all the bg pixels to dark\n",
    "# `augmentation_repetition` will concatenate n times the augmented dataset by applying the same `augmentations` fn. Useful for augmentation pipeline with probability activations\n",
    "def get_dataset(X, y, batch_size=32, augmentations=None, augmentation_repetition=1, **kwargs):\n",
    "\n",
    "  def resize_img_and_mask(img, mask):\n",
    "    input_img = tf.image.resize(img, IMG_SIZE)\n",
    "    input_img = tf.cast(input_img, tf.float32)\n",
    "\n",
    "    # Resize needs at least 3 dims, add a dummy one\n",
    "    if kwargs.get('one_hot', False):\n",
    "      mask = tf.cast(mask, tf.int32)\n",
    "      target_img = tf.one_hot(mask, depth=num_classes, axis=-1)\n",
    "    else:\n",
    "      target_img = tf.expand_dims(mask, axis=-1)\n",
    "    # Nearest-neighbor is essential for resizing segmentation masks because it preserves the discrete class labels (e.g., 0, 1, 2) without introducing unintended values due to interpolation\n",
    "    target_img = tf.image.resize(target_img, IMG_SIZE, method=\"nearest\")\n",
    "    target_img = tf.cast(target_img, tf.int32) # Consider lower integers\n",
    "\n",
    "    return input_img, target_img\n",
    "\n",
    "  def remove_background(image, mask, background_label=0):\n",
    "    background_mask = (mask == background_label)\n",
    "    image[background_mask] = 0  # Set to black\n",
    "    return image, mask\n",
    "\n",
    "  def apply_augmentation_np():\n",
    "    X_a = []\n",
    "    y_a = []\n",
    "    for i, m in zip(X, y):\n",
    "      aug_img, aug_mask = augmentations(i, m)\n",
    "      if kwargs.get('remove_bg', False):\n",
    "        aug_img, aug_mask = remove_background(aug_img, aug_mask)\n",
    "      X_a.append(aug_img)  \n",
    "      y_a.append(aug_mask)  \n",
    "    return np.array(X_a), np.array(y_a)\n",
    "  \n",
    "  if kwargs.get('remove_bg', False):\n",
    "    X_a = []\n",
    "    y_a = []\n",
    "    for i, m in zip(X, y):\n",
    "      aug_img, aug_mask = remove_background(i, m)\n",
    "      X_a.append(aug_img)\n",
    "      y_a.append(aug_mask)\n",
    "    X = np.array(X_a)\n",
    "    y = np.array(y_a)\n",
    "\n",
    "  # Apply augmentations before converting to dataset (this will be serial I think but we avoid type conversions as A works on np arrays)\n",
    "  if augmentations is not None:\n",
    "    X_a, y_a = apply_augmentation_np()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_a, y_a))\n",
    "    if augmentation_repetition > 1:\n",
    "      for i in range(augmentation_repetition-1):\n",
    "        X_a, y_a = apply_augmentation_np()\n",
    "        dataset = dataset.concatenate(tf.data.Dataset.from_tensor_slices((X_a, y_a)))\n",
    "    add_len = 0\n",
    "    if kwargs.get('additional_ds_concat', None):\n",
    "      # Optimistic\n",
    "      add_len = len(kwargs['additional_ds_concat'])\n",
    "      for pair in kwargs['additional_ds_concat']:\n",
    "        print('concatenating additional ds')\n",
    "        images, labels = pair\n",
    "        images = images.astype(np.float32)\n",
    "        dataset = dataset.concatenate(tf.data.Dataset.from_tensor_slices((images, labels)))\n",
    "    if kwargs.get('concat_and_shuffle_aug_with_no_aug', False):\n",
    "      dataset = dataset.concatenate(tf.data.Dataset.from_tensor_slices((X, y)))\n",
    "      dataset = dataset.shuffle(seed=seed, buffer_size=X.shape[0] * (augmentation_repetition+1+add_len))\n",
    "    else:\n",
    "      dataset = dataset.shuffle(seed=seed, buffer_size=X.shape[0] * (augmentation_repetition+add_len))\n",
    "\n",
    "  else:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    add_len = 0\n",
    "    if kwargs.get('additional_ds_concat', None):\n",
    "      # Optimistic\n",
    "      add_len = len(kwargs['additional_ds_concat'])\n",
    "      for pair in kwargs['additional_ds_concat']:\n",
    "        print('concatenating additional ds')\n",
    "        images, labels = pair\n",
    "        images = images.astype(np.float32)\n",
    "        dataset = dataset.concatenate(tf.data.Dataset.from_tensor_slices((images, labels)))\n",
    "    dataset = dataset.shuffle(seed=seed, buffer_size=X.shape[0] * (add_len+1))\n",
    "\n",
    "  dataset = dataset.map(resize_img_and_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "  dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlarge dataset containing images provided in the inputs\n",
    "def get_enlarged_dataset(imgs, labels, aug_fn, repetitions=2, unbatch=True, np_ds=True):\n",
    "  def apply_aug(img, mask):\n",
    "    transform = aug_fn()\n",
    "    transformed = transform(image=img, mask=mask)\n",
    "    return transformed[\"image\"], transformed[\"mask\"]\n",
    "  if np_ds:\n",
    "    X_a = []\n",
    "    y_a = []\n",
    "    for _ in range(repetitions):\n",
    "      for i, m in zip(imgs, labels):\n",
    "        aug_img, aug_mask = apply_aug(i, m)\n",
    "        X_a.append(aug_img)  \n",
    "        y_a.append(aug_mask)  \n",
    "    return np.array(X_a), np.array(y_a)\n",
    "  else:\n",
    "    enlarged_bg_dataset = get_dataset(imgs, labels, augmentations=apply_aug, augmentation_repetition=repetitions)\n",
    "    # We unbatch as this will be concatenated with other ds\n",
    "    if unbatch:\n",
    "      ds = enlarged_bg_dataset.unbatch()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the enlarged bg images dataset as example\n",
    "if not quick_run:\n",
    "  N = 10\n",
    "  a, b =  get_enlarged_dataset(noisy_images[0][0][:N], noisy_images[0][1][:N], build_augmentation_bg, np_ds=True)\n",
    "  print(a.shape, b.shape)\n",
    "  plot(a, mask=b, num_images=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸŽ² Define training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_signed_distance_map(mask):\n",
    "    \n",
    "    # Calcola la distanza esterna (distanza dai bordi del foreground)\n",
    "    inv_mask = 1 - mask\n",
    "    dist_out = tf.cast(tf.nn.relu(tf.image.sobel_edges(inv_mask)), tf.float32)\n",
    "\n",
    "    # Calcola la distanza interna (distanza dai bordi del background)\n",
    "    dist_in = tf.cast(tf.nn.relu(tf.image.sobel_edges(mask)), tf.float32)\n",
    "\n",
    "    # Combina le distanze in un unico gradiente\n",
    "    dx_out, dy_out = dist_out[..., 0], dist_out[..., 1]\n",
    "    dx_in, dy_in = dist_in[..., 0], dist_in[..., 1]\n",
    "\n",
    "    dist_out_combined = tf.sqrt(tf.square(dx_out) + tf.square(dy_out))\n",
    "    dist_in_combined = tf.sqrt(tf.square(dx_in) + tf.square(dy_in))\n",
    "\n",
    "    # Signed Distance Map: negativo all'interno, positivo all'esterno\n",
    "    sdm = dist_out_combined - dist_in_combined\n",
    "    return sdm\n",
    "\n",
    "def boundary_loss(y_true, y_pred):\n",
    "    # Calcola la Signed Distance Map\n",
    "    sdm = compute_signed_distance_map(y_true)\n",
    "    \n",
    "    # Normalizza le previsioni\n",
    "    y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
    "\n",
    "    # Calcola la boundary loss\n",
    "    loss = tf.reduce_mean(tf.abs(sdm * (y_true - y_pred)))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "  # Convert y_true to one-hot if needed\n",
    "  # TODO: should we retrieve the argmax and use 1 channels instead of 5?\n",
    "  if y_true.shape[-1] != y_pred.shape[-1]:\n",
    "      y_true = tf.one_hot(tf.cast(y_true[..., 0], tf.int32), depth=y_pred.shape[-1])\n",
    "  \n",
    "  # Compute Dice Loss per class\n",
    "  intersection = tf.reduce_sum(y_true * y_pred, axis=(1, 2))\n",
    "  union = tf.reduce_sum(y_true + y_pred, axis=(1, 2))\n",
    "  dice = (2. * intersection + smooth) / (union + smooth)\n",
    "  \n",
    "  # Average Dice Loss over all classes and batch\n",
    "  dice_loss = 1 - tf.reduce_mean(dice)\n",
    "  \n",
    "  return dice_loss\n",
    "\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "\n",
    "        loss_sparse = tfk.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "        loss_dice = dice_loss(y_true, y_pred)\n",
    "    \n",
    "        if y_true.shape[-1] != y_pred.shape[-1]:\n",
    "            y_true = tf.one_hot(tf.cast(y_true[..., 0], tf.int32), depth=y_pred.shape[-1])\n",
    "        focal_loss = tfk.losses.CategoricalFocalCrossentropy() \n",
    "    \n",
    "        loss_focal = focal_loss(y_true, y_pred)\n",
    "        loss_boundary = boundary_loss(y_true, y_pred)\n",
    "\n",
    "        # Create class masks\n",
    "        class_ids = tf.argmax(y_true, axis=-1)  # Find the class labels (integer format)\n",
    "        class_0_mask = tf.cast(tf.equal(class_ids, 0), tf.float32)\n",
    "        #class_1_mask = tf.cast(tf.equal(class_ids, 1), tf.float32)\n",
    "        class_4_mask = tf.cast(tf.equal(class_ids, 4), tf.float32)\n",
    "        other_classes_mask = 1.0 - class_0_mask - class_4_mask  # Remainder classes\n",
    "    \n",
    "        # Apply specific losses for each class\n",
    "        loss_focal = loss_focal * class_0_mask\n",
    "        loss_dice = loss_dice * class_4_mask\n",
    "        loss_sparse = loss_sparse * other_classes_mask\n",
    "\n",
    "        return loss_focal + loss_dice + loss_sparse + 0.1 * loss_boundary\n",
    "\n",
    "def get_loss():\n",
    "  if loss_fn == 'sparse_categorical_crossentropy':\n",
    "    return tfk.losses.SparseCategoricalCrossentropy()\n",
    "  elif loss_fn == 'boundary_loss':\n",
    "    return boundary_loss\n",
    "  elif loss_fn == 'dice_loss':\n",
    "    return dice_loss\n",
    "  elif loss_fn == 'combined_loss':\n",
    "    return combined_loss\n",
    "  else:\n",
    "    raise ValueError(f\"Loss function {loss_fn} not recognized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization callback\n",
    "category_map = {\n",
    "  0: 0, # Background,\n",
    "  1: 1, # Soil,\n",
    "  2: 2, # Bedrock,\n",
    "  3: 3, # Sand,\n",
    "  4: 4, # Big Rock,\n",
    "}\n",
    "\n",
    "def apply_category_mapping(label):\n",
    "  \"\"\"\n",
    "  Apply category mapping to labels.\n",
    "  \"\"\"\n",
    "  print(\"Label dtype before mapping:\", label.dtype)\n",
    "  keys_tensor = tf.constant(list(category_map.keys()), dtype=tf.int32)\n",
    "  vals_tensor = tf.constant(list(category_map.values()), dtype=tf.int32)\n",
    "  table = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor),\n",
    "    default_value=0\n",
    "  )\n",
    "  return table.lookup(label)\n",
    "\n",
    "def create_segmentation_colormap(num_classes):\n",
    "  \"\"\"\n",
    "  Create a linear colormap using a predefined palette.\n",
    "  Uses 'viridis' as default because it is perceptually uniform\n",
    "  and works well for colorblindness.\n",
    "  \"\"\"\n",
    "  return plt.cm.viridis(np.linspace(0, 1, num_classes))\n",
    "\n",
    "def apply_colormap(label, colormap=None):\n",
    "  \"\"\"\n",
    "  Apply the colormap to a label.\n",
    "  \"\"\"\n",
    "  # Ensure label is 2D\n",
    "  label = np.squeeze(label)\n",
    "\n",
    "  if colormap is None:\n",
    "    num_classes = len(np.unique(label))\n",
    "    colormap = create_segmentation_colormap(num_classes)\n",
    "\n",
    "  # Apply the colormap\n",
    "  colored = colormap[label.astype(int)]\n",
    "\n",
    "  return colored\n",
    "  \n",
    "class VizCallback(tf.keras.callbacks.Callback):\n",
    "  def __init__(self, image, label, frequency=5):\n",
    "    super().__init__()\n",
    "    self.image = image\n",
    "    self.label = tf.cast(tf.convert_to_tensor(label), tf.int32) \n",
    "    self.frequency = frequency\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    if epoch % self.frequency == 0:  # Visualize only every \"frequency\" epochs\n",
    "      image, label = self.image, self.label\n",
    "      label = apply_category_mapping(label)\n",
    "      image = tf.expand_dims(image, 0)\n",
    "      pred = self.model.predict(image, verbose=0)\n",
    "      y_pred = tf.math.argmax(pred, axis=-1)\n",
    "      y_pred = y_pred.numpy()\n",
    "\n",
    "      # Create colormap\n",
    "      num_classes = NUM_CLASSES\n",
    "      colormap = create_segmentation_colormap(num_classes)\n",
    "\n",
    "      plt.figure(figsize=(16, 4))\n",
    "\n",
    "      # Input image\n",
    "      plt.subplot(1, 3, 1)\n",
    "      plt.imshow(image[0],cmap='gray')\n",
    "      plt.title(\"Input Image\")\n",
    "      plt.axis('off')\n",
    "\n",
    "      # Ground truth\n",
    "      plt.subplot(1, 3, 2)\n",
    "      colored_label = apply_colormap(label.numpy(), colormap)\n",
    "      plt.imshow(colored_label)\n",
    "      plt.title(\"Ground Truth Mask\")\n",
    "      plt.axis('off')\n",
    "\n",
    "      # Prediction\n",
    "      plt.subplot(1, 3, 3)\n",
    "      colored_pred = apply_colormap(y_pred[0], colormap)\n",
    "      plt.imshow(colored_pred)\n",
    "      plt.title(\"Predicted Mask\")\n",
    "      plt.axis('off')\n",
    "\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "      plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T20:59:53.000513Z",
     "iopub.status.busy": "2024-11-21T20:59:53.000251Z",
     "iopub.status.idle": "2024-11-21T20:59:53.010025Z",
     "shell.execute_reply": "2024-11-21T20:59:53.009423Z",
     "shell.execute_reply.started": "2024-11-21T20:59:53.000489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define fitting callbacks. Comment out from dict the unwanted ones\n",
    "val_mask = tf.expand_dims(y_val[0], axis=-1)\n",
    "val_mask = tf.image.resize(val_mask, [IMG_SIZE[0], IMG_SIZE[1]], method=\"nearest\")\n",
    "val_img = tf.image.resize(X_val[0], [IMG_SIZE[0], IMG_SIZE[1]])\n",
    "viz_callback = VizCallback(val_img, val_mask)\n",
    "model_fit_callbacks = {\n",
    "  'ReduceLROnPlateau': tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-6, verbose=1),\n",
    "  'EarlyStopping': tfk.callbacks.EarlyStopping(monitor='val_mean_iou', mode='max', patience=50, restore_best_weights=True, verbose=1),\n",
    "  'Viz_callback' : viz_callback\n",
    "}\n",
    "\n",
    "def get_callbacks():\n",
    "  return [i for i in model_fit_callbacks.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Define model, augmentation and utils builders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_augmentation(img, mask):\n",
    "  transform = build_augmentation()\n",
    "  transformed = transform(image=img, mask=mask)\n",
    "  return transformed[\"image\"], transformed[\"mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the augmented dataset\n",
    "if not quick_run:\n",
    "  N = 2\n",
    "  ds = get_dataset(X_train[:N], y_train[:N], augmentations=apply_augmentation, augmentation_repetition=4, concat_and_shuffle_aug_with_no_aug=True)\n",
    "\n",
    "  for batch in ds.take(1):\n",
    "    a, b = batch\n",
    "    plot(a.numpy(), b.numpy(), num_images=N * 5) # use N * (augmentation_repetition+1) as `concat_and_shuffle_aug_with_no_aug` is True \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_xception(input_shape, num_cls, augmentation=None):\n",
    "    inputs = tfkl.Input(shape=input_shape)\n",
    "\n",
    "    if augmentation is not None:\n",
    "        x = augmentation(inputs)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Entry block\n",
    "    x = tfkl.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = tfkl.ReLU()(x)\n",
    "        x = tfkl.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = tfkl.BatchNormalization()(x)\n",
    "\n",
    "        x = tfkl.ReLU()(x)\n",
    "        x = tfkl.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = tfkl.BatchNormalization()(x)\n",
    "\n",
    "        x = tfkl.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = tfkl.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = tfkl.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = tfkl.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "\n",
    "    x = tfkl.GlobalAveragePooling2D()(x)\n",
    "    if num_cls == 2:\n",
    "        units = 1\n",
    "    else:\n",
    "        units = num_cls\n",
    "\n",
    "    x = tfkl.Dropout(0.25)(x)\n",
    "    outputs = tfkl.Dense(units, activation='sigmoid' if units == 1 else 'softmax')(x)\n",
    "\n",
    "    return tfk.Model(inputs=inputs, outputs=outputs, name='Xception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_classifier(input_shape, num_cls, augmentation=None):\n",
    "  assert(num_cls >= 2)\n",
    "  \n",
    "  # Define the input layer\n",
    "  input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "  # Apply optional data augmentation, then first convolutional layer\n",
    "  if augmentation == None:\n",
    "      x = tfkl.Conv2D(filters=32, kernel_size=3, padding='same', name='conv0')(input_layer)\n",
    "  else:\n",
    "      x = augmentation(input_layer)\n",
    "      x = tfkl.Conv2D(filters=32, kernel_size=3, padding='same', name='conv0')(x)\n",
    "\n",
    "  # Apply activation and pooling after the first convolution\n",
    "  x = tfkl.ReLU(name='relu0')(x)\n",
    "  x = tfkl.MaxPooling2D(name='mp0')(x)\n",
    "\n",
    "  # Apply second convolutional layer, activation, and pooling\n",
    "  #x = tfkl.Conv2D(filters=32, kernel_size=3, padding='same', name='conv1')(x)\n",
    "  #x = tfkl.ReLU(name='relu1')(x)\n",
    "  #x = tfkl.MaxPooling2D(name='mp1')(x)\n",
    "\n",
    "  # Apply third convolutional layer, activation, and pooling\n",
    "  x = tfkl.Conv2D(filters=64, kernel_size=3, padding='same', name='conv2')(x)\n",
    "  x = tfkl.ReLU(name='relu2')(x)\n",
    "  x = tfkl.MaxPooling2D(name='mp2')(x)\n",
    "\n",
    "  # Apply fourth convolutional layer, activation, and pooling\n",
    "  x = tfkl.Conv2D(filters=128, kernel_size=3, padding='same', name='conv3')(x)\n",
    "  x = tfkl.ReLU(name='relu3')(x)\n",
    "  x = tfkl.MaxPooling2D(name='mp3')(x)\n",
    "\n",
    "  x = tfkl.Flatten(name='flatten')(x)\n",
    "  x = tfkl.Dense(128, activation='relu', name='dense1')(x)\n",
    "  x = tfkl.Dropout(0.2, name='drop1')(x)\n",
    "\n",
    "  # Define the output layer\n",
    "  output_layer = tfkl.Dense(num_cls if num_cls > 2 else 1, activation='sigmoid' if num_cls == 2 else 'softmax', name='Output')(x)\n",
    "\n",
    "  # Create the model\n",
    "  model = tfk.Model(inputs=input_layer, outputs=output_layer, name='CNN')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_vgg(input_shape, num_cls, augmentation=None):\n",
    "  input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "  vgg = tfk.applications.VGG19(\n",
    "      weights=None,\n",
    "      include_top=False,\n",
    "      input_tensor=None,\n",
    "      input_shape=input_shape,\n",
    "      pooling='avg',\n",
    "  )\n",
    "\n",
    "  # Apply optional data augmentation, then first convolutional layer\n",
    "  if augmentation is None:\n",
    "    x = input_layer\n",
    "  else:\n",
    "    x = augmentation(input_layer)\n",
    "\n",
    "  x = vgg(x)\n",
    "\n",
    "  for drop, dense in zip([0.5, 0.3], [256, 128]):\n",
    "    x = tfkl.Dropout(drop)(x)\n",
    "    x = tfkl.Dense(dense, activation='relu')(x)\n",
    "  \n",
    "  x = tfkl.Dropout(0.2)(x)\n",
    "  output_layer = tfkl.Dense(num_cls if num_cls > 2 else 1, activation='sigmoid' if num_cls == 2 else 'softmax', name='Output')(x)\n",
    "  model = tfk.Model(inputs=input_layer, outputs=output_layer, name='VGG19')\n",
    "\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(name: str, input_shape: tuple, num_cls: int, augmentation=None):\n",
    "  if name == 'cnn':\n",
    "    return build_custom_classifier(input_shape=input_shape, num_cls=num_cls, augmentation=augmentation)\n",
    "  elif name == 'xception':\n",
    "    return build_classifier_xception(input_shape=input_shape, num_cls=num_cls, augmentation=augmentation)\n",
    "  elif name == 'vgg':\n",
    "    return build_classifier_vgg(input_shape=input_shape, num_cls=num_cls, augmentation=augmentation)\n",
    "  else:\n",
    "    raise ValueError('Not impl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_U_NET(img_size: tuple[int, int, int], num_classes):\n",
    "  def unet_block(input_tensor, filters, kernel_size=3, activation='relu', stack=2, name=''):\n",
    "    # Initialise the input tensor\n",
    "    x = input_tensor\n",
    "\n",
    "    # Apply a sequence of Conv2D, Batch Normalisation, and Activation layers for the specified number of stacks\n",
    "    for i in range(stack):\n",
    "        x = tfkl.Conv2D(filters, kernel_size=kernel_size, padding='same', name=name + 'conv' + str(i + 1))(x)\n",
    "        x = tfkl.BatchNormalization(name=name + 'bn' + str(i + 1))(x)\n",
    "        x = tfkl.Activation(activation, name=name + 'activation' + str(i + 1))(x)\n",
    "\n",
    "    # Return the transformed tensor\n",
    "    return x\n",
    "\n",
    "  input_layer = tfkl.Input(shape=img_size, name='input_layer')\n",
    "\n",
    "  # Downsampling path\n",
    "  down_block_1 = unet_block(input_layer, 32, name='down_block1_')\n",
    "  d1 = tfkl.MaxPooling2D()(down_block_1)\n",
    "\n",
    "  down_block_2 = unet_block(d1, 64, name='down_block2_')\n",
    "  d2 = tfkl.MaxPooling2D()(down_block_2)\n",
    "\n",
    "  # Bottleneck\n",
    "  bottleneck = unet_block(d2, 128, name='bottleneck')\n",
    "\n",
    "  # Upsampling path\n",
    "  u1 = tfkl.UpSampling2D()(bottleneck)\n",
    "  u1 = tfkl.Concatenate()([u1, down_block_2])\n",
    "  u1 = unet_block(u1, 64, name='up_block1_')\n",
    "\n",
    "  u2 = tfkl.UpSampling2D()(u1)\n",
    "  u2 = tfkl.Concatenate()([u2, down_block_1])\n",
    "  u2 = unet_block(u2, 32, name='up_block2_')\n",
    "\n",
    "  # Output Layer\n",
    "  if num_classes==1:\n",
    "    output_layer = tfkl.Conv2D(1, kernel_size=1, padding='same', activation=\"sigmoid\", name='output_layer')(u2)\n",
    "  else:\n",
    "    output_layer = tfkl.Conv2D(num_classes, kernel_size=1, padding='same', activation=\"softmax\", name='output_layer')(u2)\n",
    "\n",
    "  model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='UNet')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ATTENTION_UW_NET(img_size: tuple[int, int, int], num_classes):\n",
    "  def attention_block(x, g, inter_channel):\n",
    "    # theta_x (bs, h, w, inter_channel)\n",
    "    theta_x = tfkl.Conv2D(inter_channel, [1, 1], strides=[1, 1])(x)\n",
    "    \n",
    "    # phi_g (bs, h, w, inter_channel)\n",
    "    phi_g = tfkl.Conv2D(inter_channel, [1, 1], strides=[1, 1])(g)\n",
    "    \n",
    "    # f (bs, h, w, 1)\n",
    "    f = tfkl.Activation('relu')(tfkl.Add()([theta_x, phi_g]))\n",
    "    psi_f = tfkl.Conv2D(1, [1, 1], strides=[1, 1])(f)\n",
    "    \n",
    "    # sigmoid_psi_f (bs, h, w, 1)\n",
    "    sigmoid_psi_f = tfkl.Activation('sigmoid')(psi_f)\n",
    "    \n",
    "    # rate (bs, h, w, 1)\n",
    "    rate = tfkl.multiply([x, sigmoid_psi_f])\n",
    "    \n",
    "    return rate\n",
    "  \n",
    "  # Input\n",
    "  inputs = tfkl.Input(shape=img_size)\n",
    "  \n",
    "  # Encoder Path\n",
    "  # Block 1\n",
    "  conv1 = tfkl.Conv2D(64, 3, padding='same')(inputs)\n",
    "  conv1 = tfkl.BatchNormalization()(conv1)\n",
    "  conv1 = tfkl.Activation('relu')(conv1)\n",
    "  conv1 = tfkl.Conv2D(64, 3, padding='same')(conv1)\n",
    "  conv1 = tfkl.BatchNormalization()(conv1)\n",
    "  conv1 = tfkl.Activation('relu')(conv1)\n",
    "  pool1 = tfkl.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "  \n",
    "  # Block 2\n",
    "  conv2 = tfkl.Conv2D(128, 3, padding='same')(pool1)\n",
    "  conv2 = tfkl.BatchNormalization()(conv2)\n",
    "  conv2 = tfkl.Activation('relu')(conv2)\n",
    "  conv2 = tfkl.Conv2D(128, 3, padding='same')(conv2)\n",
    "  conv2 = tfkl.BatchNormalization()(conv2)\n",
    "  conv2 = tfkl.Activation('relu')(conv2)\n",
    "  pool2 = tfkl.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "  \n",
    "  # Block 3\n",
    "  conv3 = tfkl.Conv2D(256, 3, padding='same')(pool2)\n",
    "  conv3 = tfkl.BatchNormalization()(conv3)\n",
    "  conv3 = tfkl.Activation('relu')(conv3)\n",
    "  conv3 = tfkl.Conv2D(256, 3, padding='same')(conv3)\n",
    "  conv3 = tfkl.BatchNormalization()(conv3)\n",
    "  conv3 = tfkl.Activation('relu')(conv3)\n",
    "  pool3 = tfkl.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "  \n",
    "  # Block 4\n",
    "  conv4 = tfkl.Conv2D(512, 3, padding='same')(pool3)\n",
    "  conv4 = tfkl.BatchNormalization()(conv4)\n",
    "  conv4 = tfkl.Activation('relu')(conv4)\n",
    "  conv4 = tfkl.Conv2D(512, 3, padding='same')(conv4)\n",
    "  conv4 = tfkl.BatchNormalization()(conv4)\n",
    "  conv4 = tfkl.Activation('relu')(conv4)\n",
    "  pool4 = tfkl.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "  \n",
    "  # Bridge\n",
    "  conv5 = tfkl.Conv2D(1024, 3, padding='same')(pool4)\n",
    "  conv5 = tfkl.BatchNormalization()(conv5)\n",
    "  conv5 = tfkl.Activation('relu')(conv5)\n",
    "  conv5 = tfkl.Conv2D(1024, 3, padding='same')(conv5)\n",
    "  conv5 = tfkl.BatchNormalization()(conv5)\n",
    "  conv5 = tfkl.Activation('relu')(conv5)\n",
    "  \n",
    "  # Decoder Path with Attention\n",
    "  # Block 6\n",
    "  up6 = tfkl.Conv2D(512, 2, padding='same')(tfkl.UpSampling2D(size=(2, 2))(conv5))\n",
    "  up6 = tfkl.BatchNormalization()(up6)\n",
    "  up6 = tfkl.Activation('relu')(up6)\n",
    "  \n",
    "  att6 = attention_block(conv4, up6, inter_channel=256)\n",
    "  merge6 = tfkl.concatenate([att6, up6], axis=3)\n",
    "  \n",
    "  conv6 = tfkl.Conv2D(512, 3, padding='same')(merge6)\n",
    "  conv6 = tfkl.BatchNormalization()(conv6)\n",
    "  conv6 = tfkl.Activation('relu')(conv6)\n",
    "  conv6 = tfkl.Conv2D(512, 3, padding='same')(conv6)\n",
    "  conv6 = tfkl.BatchNormalization()(conv6)\n",
    "  conv6 = tfkl.Activation('relu')(conv6)\n",
    "  \n",
    "  # Block 7\n",
    "  up7 = tfkl.Conv2D(256, 2, padding='same')(tfkl.UpSampling2D(size=(2, 2))(conv6))\n",
    "  up7 = tfkl.BatchNormalization()(up7)\n",
    "  up7 = tfkl.Activation('relu')(up7)\n",
    "  \n",
    "  att7 = attention_block(conv3, up7, inter_channel=128)\n",
    "  merge7 = tfkl.concatenate([att7, up7], axis=3)\n",
    "  \n",
    "  conv7 = tfkl.Conv2D(256, 3, padding='same')(merge7)\n",
    "  conv7 = tfkl.BatchNormalization()(conv7)\n",
    "  conv7 = tfkl.Activation('relu')(conv7)\n",
    "  conv7 = tfkl.Conv2D(256, 3, padding='same')(conv7)\n",
    "  conv7 = tfkl.BatchNormalization()(conv7)\n",
    "  conv7 = tfkl.Activation('relu')(conv7)\n",
    "  \n",
    "  # Block 8\n",
    "  up8 = tfkl.Conv2D(128, 2, padding='same')(tfkl.UpSampling2D(size=(2, 2))(conv7))\n",
    "  up8 = tfkl.BatchNormalization()(up8)\n",
    "  up8 = tfkl.Activation('relu')(up8)\n",
    "  \n",
    "  att8 = attention_block(conv2, up8, inter_channel=64)\n",
    "  merge8 = tfkl.concatenate([att8, up8], axis=3)\n",
    "  \n",
    "  conv8 = tfkl.Conv2D(128, 3, padding='same')(merge8)\n",
    "  conv8 = tfkl.BatchNormalization()(conv8)\n",
    "  conv8 = tfkl.Activation('relu')(conv8)\n",
    "  conv8 = tfkl.Conv2D(128, 3, padding='same')(conv8)\n",
    "  conv8 = tfkl.BatchNormalization()(conv8)\n",
    "  conv8 = tfkl.Activation('relu')(conv8)\n",
    "  \n",
    "  # Block 9\n",
    "  up9 = tfkl.Conv2D(64, 2, padding='same')(tfkl.UpSampling2D(size=(2, 2))(conv8))\n",
    "  up9 = tfkl.BatchNormalization()(up9)\n",
    "  up9 = tfkl.Activation('relu')(up9)\n",
    "  \n",
    "  att9 = attention_block(conv1, up9, inter_channel=32)\n",
    "  merge9 = tfkl.concatenate([att9, up9], axis=3)\n",
    "  \n",
    "  conv9 = tfkl.Conv2D(64, 3, padding='same')(merge9)\n",
    "  conv9 = tfkl.BatchNormalization()(conv9)\n",
    "  conv9 = tfkl.Activation('relu')(conv9)\n",
    "  conv9 = tfkl.Conv2D(64, 3, padding='same')(conv9)\n",
    "  conv9 = tfkl.BatchNormalization()(conv9)\n",
    "  conv9 = tfkl.Activation('relu')(conv9)\n",
    "  \n",
    "  # Output\n",
    "  if num_classes == 1:\n",
    "    outputs = tfkl.Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "  else:\n",
    "    outputs = tfkl.Conv2D(num_classes, 1, activation='softmax')(conv9)\n",
    "  \n",
    "  model = tfk.Model(inputs=inputs, outputs=outputs, name='AttentionUWNet')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ASPP_model(img_size: tuple[int, int, int], num_classes: int):\n",
    "  \n",
    "  initializer = tf.keras.initializers.HeNormal()\n",
    "  regularizer = tf.keras.regularizers.l2(1e-4)\n",
    "\n",
    "  inputs = tfkl.Input(shape=img_size)\n",
    "\n",
    "  def conv_block(x, filters, kernel_size=(3, 3), activation=\"relu\", batch_norm=True, dropout_rate=0.2):\n",
    "    x = tfkl.Conv2D(\n",
    "      filters,\n",
    "      kernel_size,\n",
    "      padding=\"same\",\n",
    "      kernel_initializer=initializer,\n",
    "      kernel_regularizer=regularizer,\n",
    "    )(x)\n",
    "    if batch_norm:\n",
    "      x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Activation(activation)(x)\n",
    "    if dropout_rate > 0:\n",
    "      x = tfkl.SpatialDropout2D(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "  def encoder_block(x, filters, dropout_rate=0.2):\n",
    "    x = conv_block(x, filters, dropout_rate=dropout_rate)\n",
    "    x = conv_block(x, filters, dropout_rate=dropout_rate)\n",
    "    p = tfkl.MaxPooling2D(2)(x)\n",
    "    return x, p\n",
    "\n",
    "  def atrous_spatial_pyramid_pooling(x, dropout_rate=0.3):\n",
    "    dims = x.shape[1:3]\n",
    "    pool = tfkl.GlobalAveragePooling2D()(x)\n",
    "    pool = tfkl.Reshape((1, 1, x.shape[-1]))(pool)\n",
    "    pool = tfkl.Conv2D(\n",
    "      256, \n",
    "      1, \n",
    "      padding=\"same\", \n",
    "      kernel_initializer=initializer, \n",
    "      kernel_regularizer=regularizer,\n",
    "    )(pool)\n",
    "    pool = tfkl.UpSampling2D(size=dims, interpolation=\"bilinear\")(pool)\n",
    "    pool = tfkl.SpatialDropout2D(dropout_rate)(pool)\n",
    "\n",
    "    conv_1x1 = tfkl.Conv2D(\n",
    "      256,\n",
    "      1,\n",
    "      padding=\"same\",\n",
    "      kernel_initializer=initializer,\n",
    "      kernel_regularizer=regularizer,\n",
    "    )(x)\n",
    "    atrous_6 = tfkl.Conv2D(\n",
    "      256,\n",
    "      3,\n",
    "      dilation_rate=6,\n",
    "      padding=\"same\",\n",
    "      kernel_initializer=initializer,\n",
    "      kernel_regularizer=regularizer,\n",
    "    )(x)\n",
    "    atrous_12 = tfkl.Conv2D(\n",
    "      256,\n",
    "      3,\n",
    "      dilation_rate=12,\n",
    "      padding=\"same\",\n",
    "      kernel_initializer=initializer,\n",
    "      kernel_regularizer=regularizer,\n",
    "    )(x)\n",
    "    atrous_18 = tfkl.Conv2D(\n",
    "      256,\n",
    "      3,\n",
    "      dilation_rate=18,\n",
    "      padding=\"same\",\n",
    "      kernel_initializer=initializer,\n",
    "      kernel_regularizer=regularizer,\n",
    "    )(x)\n",
    "\n",
    "    x = tfkl.Concatenate()([pool, conv_1x1, atrous_6, atrous_12, atrous_18])\n",
    "    x = tfkl.Conv2D(\n",
    "      256,\n",
    "      1,\n",
    "      padding=\"same\",\n",
    "      kernel_initializer=initializer,\n",
    "      kernel_regularizer=regularizer,\n",
    "    )(x)\n",
    "    x = tfkl.SpatialDropout2D(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "  def decoder_block(x, skip, filters, dropout_rate=0.2):\n",
    "    x = tfkl.Conv2DTranspose(\n",
    "      filters,\n",
    "      2,\n",
    "      strides=2,\n",
    "      padding=\"same\",\n",
    "      kernel_initializer=initializer,\n",
    "      kernel_regularizer=regularizer,\n",
    "    )(x)\n",
    "    x = tfkl.Concatenate()([x, skip])\n",
    "    x = conv_block(x, filters, dropout_rate=dropout_rate)\n",
    "    return x\n",
    "\n",
    "  # Encoder\n",
    "  filters = [64, 128, 256, 512]\n",
    "  skips = []\n",
    "  x = inputs\n",
    "  for f in filters:\n",
    "    skip, x = encoder_block(x, f, dropout_rate=0.2)\n",
    "    skips.append(skip)\n",
    "\n",
    "  # Bottleneck with ASPP\n",
    "  x = conv_block(x, 1024, dropout_rate=0.3)\n",
    "  x = atrous_spatial_pyramid_pooling(x, dropout_rate=0.3)\n",
    "\n",
    "  # Decoder\n",
    "  skips = skips[::-1]\n",
    "  decoder_filters = [512, 256, 128, 64]\n",
    "  for skip, f in zip(skips, decoder_filters):\n",
    "    x = decoder_block(x, skip, f, dropout_rate=0.2)\n",
    "\n",
    "  # Final convolutional layer\n",
    "  outputs = tfkl.Conv2D(\n",
    "    num_classes, \n",
    "    1, \n",
    "    activation=\"softmax\", \n",
    "    kernel_initializer=initializer, \n",
    "    kernel_regularizer=regularizer,\n",
    "  )(x)\n",
    "\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "  'U_NET': build_U_NET,\n",
    "  'UWNet': build_ATTENTION_UW_NET,\n",
    "  'ASPP' : build_ASPP_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T21:00:15.940614Z",
     "iopub.status.busy": "2024-11-21T21:00:15.940360Z",
     "iopub.status.idle": "2024-11-21T21:00:15.949708Z",
     "shell.execute_reply": "2024-11-21T21:00:15.948895Z",
     "shell.execute_reply.started": "2024-11-21T21:00:15.940588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, cw=class_weights, data_loader=None, epochs=100, validation_data_loader=None):\n",
    "  assert(data_loader is not None)\n",
    "  assert(validation_data_loader is not None)\n",
    "  fit_history = model.fit(\n",
    "        data_loader,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_data_loader,\n",
    "        class_weight=cw,\n",
    "        callbacks=get_callbacks()\n",
    "      ).history\n",
    "  return fit_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T21:00:15.980359Z",
     "iopub.status.busy": "2024-11-21T21:00:15.980111Z",
     "iopub.status.idle": "2024-11-21T21:00:15.995129Z",
     "shell.execute_reply": "2024-11-21T21:00:15.994358Z",
     "shell.execute_reply.started": "2024-11-21T21:00:15.980335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Taken from https://github.com/SeanSdahl/RangerOptimizerTensorflow/blob/master/module.py\n",
    "def build_ranger(lr=1e-3, weight_decay=0.0):\n",
    "  try:\n",
    "    import tensorflow_addons as tfa\n",
    "  except:\n",
    "    raise Exception(\"You have to install tensorflow_addons package for Ranger. Please note that this package is available up to tensorflow==2.14\")\n",
    "  def ranger(sync_period=6,\n",
    "      slow_step_size=0.5,\n",
    "      learning_rate=lr,\n",
    "      beta_1=0.9,\n",
    "      beta_2=0.999,\n",
    "      epsilon=1e-7,\n",
    "      weight_decay=weight_decay,\n",
    "      amsgrad=False,\n",
    "      sma_threshold=5.0,\n",
    "      total_steps=0,\n",
    "      warmup_proportion=0.1,\n",
    "      min_lr=0.,\n",
    "      name=\"Ranger\"):\n",
    "    inner = tfa.optimizers.RectifiedAdam(learning_rate, beta_1, beta_2, epsilon, weight_decay, amsgrad, sma_threshold, total_steps, warmup_proportion, min_lr, name)\n",
    "    optim = tfa.optimizers.Lookahead(inner, sync_period, slow_step_size, name)\n",
    "    return optim\n",
    "  return ranger()\n",
    "\n",
    "def get_optimizer(opt, batch_size, lr, **kwargs):\n",
    "  decay = opt_exp_decay_rate\n",
    "  if opt == \"SGD\":\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9 if 'momentum' not in kwargs else kwargs['momentum'])\n",
    "    if decay is not None:\n",
    "      lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "          initial_learning_rate= lr,\n",
    "          decay_steps=opt_decay_epoch_delta * (X_train.shape[0] // batch_size),  # Decay every 7 epochs\n",
    "          decay_rate=opt_exp_decay_rate,\n",
    "          staircase=True\n",
    "      )\n",
    "      optimizer.learning_rate = lr_schedule\n",
    "      print(f'Using {opt} optimizer with exp decay {decay} (momentum = {optimizer.momentum})')\n",
    "      return optimizer\n",
    "    else:\n",
    "      optimizer.learning_rate = lr\n",
    "      print(f'Using {opt} optimizer (momentum = {optimizer.momentum})')\n",
    "      return optimizer\n",
    "\n",
    "  elif opt == \"Adam\":\n",
    "    if 'weight_decay' in kwargs:\n",
    "      optimizer = tf.keras.optimizers.Adam(weight_decay=kwargs['weight_decay'])\n",
    "    else:\n",
    "      optimizer = tf.keras.optimizers.Adam()\n",
    "    if decay is not None:\n",
    "      lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "          initial_learning_rate=lr,\n",
    "          decay_steps=opt_decay_epoch_delta * (X_train.shape[0] // batch_size),  # Decay every 7 epochs\n",
    "          decay_rate=opt_exp_decay_rate,\n",
    "          staircase=True\n",
    "      )\n",
    "      optimizer.learning_rate = lr_schedule\n",
    "      print(f'Using {opt} optimizer with exp decay of {decay} weight decay = {optimizer.weight_decay}')\n",
    "      return optimizer\n",
    "    else:\n",
    "      optimizer.learning_rate = lr\n",
    "      print(f'Using {opt} optimizer (weight decay = {optimizer.weight_decay})')\n",
    "      return optimizer\n",
    "\n",
    "  elif opt == \"AdamW\":\n",
    "    if 'weight_decay' in kwargs:\n",
    "      optimizer = tf.keras.optimizers.AdamW(weight_decay=kwargs['weight_decay'])\n",
    "    else:\n",
    "      optimizer = tf.keras.optimizers.AdamW()\n",
    "    if decay is not None:\n",
    "      lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "          initial_learning_rate= lr,\n",
    "          decay_steps=opt_decay_epoch_delta * (X_train.shape[0] // batch_size),  # Decay every 7 epochs\n",
    "          decay_rate=opt_exp_decay_rate,\n",
    "          staircase=True\n",
    "      )\n",
    "      optimizer.learning_rate = lr_schedule\n",
    "      print(f'Using {opt} optimizer with exp decay of {decay} weight decay = {optimizer.weight_decay}')\n",
    "      return optimizer\n",
    "    else:\n",
    "      optimizer.learning_rate = lr\n",
    "      print(f'Using {opt} optimizer (weight decay = {optimizer.weight_decay})')\n",
    "      return optimizer\n",
    "\n",
    "  elif opt == \"Lion\":\n",
    "    if 'weight_decay' in kwargs:\n",
    "      optimizer = tf.keras.optimizers.Lion(weight_decay=kwargs['weight_decay'])\n",
    "    else:\n",
    "      optimizer = tf.keras.optimizers.Lion()\n",
    "    if decay is not None:\n",
    "      lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "          initial_learning_rate= lr,\n",
    "          decay_steps=opt_decay_epoch_delta * (X_train.shape[0] // batch_size),  # Decay every 7 epochs\n",
    "          decay_rate=opt_exp_decay_rate,\n",
    "          staircase=True\n",
    "      )\n",
    "      optimizer.learning_rate = lr_schedule\n",
    "      print(f'Using {opt} optimizer with exp decay of {decay} weight decay = {optimizer.weight_decay}')\n",
    "      return optimizer\n",
    "    else:\n",
    "      optimizer.learning_rate = lr\n",
    "      print(f'Using {opt} optimizer (weight decay = {optimizer.weight_decay})')\n",
    "      return optimizer\n",
    "  elif opt == \"Ranger\":\n",
    "    optimizer = build_ranger(lr=lr, weight_decay=0.0 if 'weight_decay' not in kwargs else kwargs['weight_decay'])\n",
    "    if decay is not None:\n",
    "      raise RuntimeError(\"Not supported\")\n",
    "    else:\n",
    "      optimizer.learning_rate = lr\n",
    "      print(f'Uusing {opt} optimizer')\n",
    "      return optimizer\n",
    "  print(f\"Starting learning rate: {lr} and batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T21:00:15.996454Z",
     "iopub.status.busy": "2024-11-21T21:00:15.996146Z",
     "iopub.status.idle": "2024-11-21T21:00:16.006383Z",
     "shell.execute_reply": "2024-11-21T21:00:16.005722Z",
     "shell.execute_reply.started": "2024-11-21T21:00:15.996418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display_model(model, force=False):\n",
    "  if not quick_run or force:\n",
    "    # Display a summary of the model architecture\n",
    "    model.summary(expand_nested=True)\n",
    "    # Display model architecture with layer shapes and trainable parameters\n",
    "    tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)\n",
    "  else:\n",
    "    # Just print the total parameters\n",
    "    print(f\"Total parameters: {model.count_params()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§—ðŸ»â€â™‚ï¸ Train and save noisy-wellsegmented classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_batch_size = 64\n",
    "classifier_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOT_PIXELS = IMG_SIZE[0] * IMG_SIZE[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data_for_binary_classifier(X: np.ndarray, y: np.ndarray, threshold=0.85):\n",
    "  NOISY = 0\n",
    "  SEGMENTED = 1\n",
    "  assert(X.shape[0] == y.shape[0])\n",
    "  labels = []\n",
    "  for _, label in zip(X, y):\n",
    "      unique, counts = np.unique(label, return_counts=True)\n",
    "      f = False\n",
    "      for u, c in zip(unique, counts):\n",
    "        if c / TOT_PIXELS >= threshold: \n",
    "          labels.append(NOISY)\n",
    "          f = True\n",
    "      if not f:\n",
    "        labels.append(SEGMENTED)\n",
    "  return X, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "# Test\n",
    "a, b = format_data_for_binary_classifier(X_train[:N], y_train[:N])\n",
    "print(b)\n",
    "plot(a, mask=y_train[:N], num_images=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce data for classifier\n",
    "X_train_classifier, y_train_classifier = format_data_for_binary_classifier(X_train, y_train)\n",
    "X_val_classifier, y_val_classifier = format_data_for_binary_classifier(X_val, y_val)\n",
    "X_test_classifier, y_test_classifier = format_data_for_binary_classifier(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = tf.keras.Sequential([\n",
    "  #tfkl.RandomTranslation(0.1, 0.1),                        # Randomly translate images by Â±10% in x and y\n",
    "  #tfkl.RandomZoom(0.2),  # Zoom (20%)\n",
    "  tfkl.RandomFlip(\"horizontal\"),  # Horizontal flip\n",
    "  tfkl.RandomRotation(0.15),  # Rotation (15%)\n",
    "  #tfkl.RandomFlip(\"vertical\"),  # Vertical flip\n",
    "  #tfkl.RandomBrightness(0.2),  # Brightness range\n",
    "], name='augmentations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_classifier('cnn', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 1), num_cls=2, augmentation=augmentation)\n",
    "display_model(model, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adamW',\n",
    "                         loss='binary_crossentropy',\n",
    "                         metrics=['accuracy'])\n",
    "early_stopping = tfk.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Store the callback in a list\n",
    "callbacks = [early_stopping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((X_train_classifier[0][0,:] * 255).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with early stopping callback\n",
    "history = model.fit(\n",
    "    x=X_train_classifier,\n",
    "    y=y_train_classifier,\n",
    "    batch_size=classifier_batch_size,\n",
    "    epochs=classifier_epochs,\n",
    "    validation_data=(X_val_classifier, y_val_classifier),\n",
    "    callbacks=callbacks\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_accuracy = round(max(history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'binary-cnn{final_val_accuracy}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cnn_training(history):\n",
    "  # Plot the training\n",
    "  plt.figure(figsize=(15,5))\n",
    "  plt.plot(history['loss'], alpha=.3, color='#ff7f0e', label='Trainig loss', linestyle='--')\n",
    "  plt.plot(history['val_loss'], label='Validation loss', alpha=.8, color='#ff7f0e')\n",
    "  plt.legend(loc='upper left')\n",
    "  plt.title('Binary Crossentropy')\n",
    "  plt.grid(alpha=.3)\n",
    "  \n",
    "  plt.figure(figsize=(15,5))\n",
    "  plt.plot(history['accuracy'], alpha=.3, color='#ff7f0e', label='Training Loss', linestyle='--')\n",
    "  plt.plot(history['val_accuracy'], label='Validation loss', alpha=.8, color='#ff7f0e')\n",
    "  plt.legend(loc='upper left')\n",
    "  plt.title('Accuracy')\n",
    "  plt.grid(alpha=.3)\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cnn_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cnn_prediction(m, X, y):\n",
    "  from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "  import seaborn as sns\n",
    "  predictions = m.predict(X, verbose=1)\n",
    "  print(\"Predictions Shape:\", predictions.shape)\n",
    "  pred_classes = (predictions > 0.5).astype(int)\n",
    "  true_classes = y.astype(int)  # Ensure ground truth is in binary form (0 or 1)\n",
    "  accuracy = accuracy_score(true_classes, pred_classes)\n",
    "  print(f'Accuracy score over the test set: {round(accuracy, 4)}')\n",
    "  precision = precision_score(true_classes, pred_classes, average='binary')\n",
    "  print(f'Precision score over the test set: {round(precision, 4)}')\n",
    "  recall = recall_score(true_classes, pred_classes, average='binary')\n",
    "  print(f'Recall score over the test set: {round(recall, 4)}')\n",
    "  f1 = f1_score(true_classes, pred_classes, average='binary')\n",
    "  print(f'F1 score over the test set: {round(f1, 4)}')\n",
    "  cm = confusion_matrix(true_classes, pred_classes)\n",
    "  annot = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
    "  plt.figure(figsize=(10, 8))\n",
    "  sns.heatmap(cm, annot=annot, fmt='', xticklabels=['Noisy', 'Well segmented'], yticklabels=['Noisy', 'Well segmented'], cmap='Blues')\n",
    "  plt.xlabel('True labels')\n",
    "  plt.ylabel('Predicted labels')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cnn_prediction(model, X_test_classifier, y_test_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data for multi class classifier\n",
    "def format_data_multiclass_classifier(X, y, y_bin, threshold=0.85):\n",
    "  #print(X.shape, y.shape, y_bin.shape)\n",
    "  num_zeros = np.size(y_bin) - np.count_nonzero(y_bin)\n",
    "  print('Total imgs out from filter:', num_zeros)\n",
    "\n",
    "  segmented_indices = [] \n",
    "  imgs = []\n",
    "  masks = []\n",
    "  labels = []\n",
    "  for i, (img, label, label_bin) in enumerate(zip (X, y, y_bin)): \n",
    "    # Ok for segmentation task\n",
    "    if int(label_bin) == 1:\n",
    "      segmented_indices.append(i)\n",
    "      continue\n",
    "\n",
    "    # Ok for classification task\n",
    "    unique, counts = np.unique(label, return_counts=True)\n",
    "    f = False\n",
    "    for u, c in zip(unique, counts):\n",
    "      if c / TOT_PIXELS >= threshold: \n",
    "        labels.append(u)\n",
    "        imgs.append(img)\n",
    "        masks.append(label)\n",
    "        f = True\n",
    "        break\n",
    "    if not f:\n",
    "      raise RuntimeError('Should not be here')\n",
    "  print(f'Total images discarded (well segmented): {len(segmented_indices)}') \n",
    "  return np.array(imgs), np.array(masks), np.array(labels), segmented_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_multi_classifier, y_train_multi_classifier_mask, y_train_multi_classifier, seg_index_train = format_data_multiclass_classifier(X_train, y_train, y_train_classifier)\n",
    "X_val_multi_classifier, y_val_multi_classifier_mask, y_val_multi_classifier, seg_index_val = format_data_multiclass_classifier(X_val, y_val, y_val_classifier)\n",
    "X_test_multi_classifier, y_test_multi_classifier_mask, y_test_multi_classifier, seg_index_test = format_data_multiclass_classifier(X_test, y_test, y_test_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check labels\n",
    "N = 4\n",
    "print(y_train_multi_classifier[:N])\n",
    "plot(X_train_multi_classifier, mask=y_train_multi_classifier_mask, num_images=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use 4 classes as the last class has no items\n",
    "model_multi = build_classifier('cnn', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 1), num_cls=4, augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class weights and use them if needed\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Get unique elements and their counts\n",
    "unique_elements, counts = np.unique(y_train_multi_classifier, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for element, count in zip(unique_elements, counts):\n",
    "    print(f\"{element} freq = {count}\")\n",
    "\n",
    "# Make weights proportional to class imbalance\n",
    "class_weight_dict_multi_classification = dict(enumerate(compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=np.unique(y_train_multi_classifier), \n",
    "    y=np.ravel(y_train_multi_classifier)\n",
    ")))\n",
    "from pprint import pprint\n",
    "print('Class weights:')\n",
    "pprint(class_weight_dict_multi_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_cv\n",
    "model_multi.compile(optimizer=tfk.optimizers.AdamW(1e-3),\n",
    "                         loss=keras_cv.losses.FocalLoss(label_smoothing=0.1),\n",
    "                         metrics=['accuracy'])\n",
    "early_stopping = tfk.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=30,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Store the callback in a list\n",
    "callbacks = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with early stopping callback\n",
    "history = model_multi.fit(\n",
    "    x=X_train_multi_classifier,\n",
    "    y=tfk.utils.to_categorical(y_train_multi_classifier),\n",
    "    batch_size=classifier_batch_size,\n",
    "    epochs=classifier_epochs,\n",
    "    validation_data=(X_val_multi_classifier, tfk.utils.to_categorical(y_val_multi_classifier)),\n",
    "    callbacks=callbacks\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_accuracy = round(max(history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cnn_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "  0: \"Background\",\n",
    "  1: \"Soil\",\n",
    "  2: \"Bedrock\",\n",
    "  3: \"Sand\",\n",
    "}\n",
    "def plot_cnn_multi_prediction(m, X, y):\n",
    "  from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "  import seaborn as sns\n",
    "  predictions = m.predict(X, verbose=1)\n",
    "  print(\"Predictions Shape:\", predictions.shape)\n",
    "  pred_classes = np.argmax(predictions, axis=-1)\n",
    "  true_classes = np.argmax(y, axis=-1)\n",
    "  accuracy = accuracy_score(true_classes, pred_classes)\n",
    "  print(f'Accuracy score over the test set: {round(100 * accuracy, 2)}%')\n",
    "  precision = precision_score(true_classes, pred_classes, average='weighted')\n",
    "  print(f'Precision score over the test set: {round(100 * precision, 2)}%')\n",
    "  recall = recall_score(true_classes, pred_classes, average='weighted')\n",
    "  print(f'Recall score over the test set: {round(100 * recall, 2)}%')\n",
    "  f1 = f1_score(true_classes, pred_classes, average='weighted')\n",
    "  print(f'F1 score over the test set: {round(100 * f1, 2)}%')\n",
    "  cm = confusion_matrix(true_classes, pred_classes)\n",
    "  cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "  annot = np.array([f\"{num}\\n({percent:.2f}%)\" for num, percent in zip(cm.flatten(), cm_percentage.flatten())]).reshape(cm.shape)\n",
    "  plt.figure(figsize=(10, 8))\n",
    "  sns.heatmap(cm_percentage.T, annot=annot, fmt='', xticklabels=list(labels.values()), yticklabels=list(labels.values()), cmap='Blues')\n",
    "  plt.xlabel('True labels')\n",
    "  plt.ylabel('Predicted labels')\n",
    "  plt.title('Confusion Matrix (Percentages)')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cnn_multi_prediction(model_multi, X_test_multi_classifier, tfk.utils.to_categorical(y_test_multi_classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi.save(f'multi-cnn{final_val_accuracy}.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§—ðŸ»â€â™‚ï¸ Train and save segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out dataset for segmentation task\n",
    "X_train_seg = X_train[seg_index_train]\n",
    "y_train_seg = y_train[seg_index_train]\n",
    "X_val_seg = X_val[seg_index_val]\n",
    "y_val_seg = y_val[seg_index_val]\n",
    "X_test_seg = X_test[seg_index_test]\n",
    "y_test_seg = y_test[seg_index_test]\n",
    "print(f'Train shapes: {X_train_seg.shape} {y_train_seg.shape}')\n",
    "print(f'Val shapes: {X_val_seg.shape} {y_val_seg.shape}')\n",
    "print(f'Test shapes: {X_test_seg.shape} {y_test_seg.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom Mean Intersection Over Union metric: the competition excludes the background class\n",
    "class MeanIntersectionOverUnion(tf.keras.metrics.MeanIoU):\n",
    "  def __init__(self, num_classes, labels_to_exclude=None, name=\"mean_iou\", dtype=None):\n",
    "    super(MeanIntersectionOverUnion, self).__init__(num_classes=num_classes, name=name, dtype=dtype)\n",
    "    self.labels_to_exclude = labels_to_exclude\n",
    "\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    # Convert predictions to class labels\n",
    "    y_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "\n",
    "    # Flatten the tensors\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "\n",
    "    # Apply mask to exclude specified labels\n",
    "    for label in self.labels_to_exclude:\n",
    "      mask = tf.not_equal(y_true, label)\n",
    "      y_true = tf.boolean_mask(y_true, mask)\n",
    "      y_pred = tf.boolean_mask(y_pred, mask)\n",
    "\n",
    "    # Update the state\n",
    "    return super().update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(fit):\n",
    "  # Plot and display training and validation loss\n",
    "  plt.figure(figsize=(18, 3))\n",
    "  plt.plot(fit['loss'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\n",
    "  plt.plot(fit['val_loss'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\n",
    "  plt.title('Cross Entropy')\n",
    "  plt.legend()\n",
    "  plt.grid(alpha=0.3)\n",
    "  plt.show()\n",
    "\n",
    "  # Plot and display training and validation accuracy\n",
    "  plt.figure(figsize=(18, 3))\n",
    "  plt.plot(fit['accuracy'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\n",
    "  plt.plot(fit['val_accuracy'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\n",
    "  plt.title('Accuracy')\n",
    "  plt.legend()\n",
    "  plt.grid(alpha=0.3)\n",
    "  plt.show()\n",
    "\n",
    "  # Plot and display training and validation mean IoU\n",
    "  plt.figure(figsize=(18, 3))\n",
    "  plt.plot(fit['mean_iou'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\n",
    "  plt.plot(fit['val_mean_iou'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\n",
    "  plt.title('Mean Intersection over Union')\n",
    "  plt.legend()\n",
    "  plt.grid(alpha=0.3)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_triptychs(dataset, model, num_batches=1):\n",
    "  \"\"\"\n",
    "  Plot triptychs (original image, true mask, predicted mask) for samples from a tf.data.Dataset\n",
    "\n",
    "  Parameters:\n",
    "  dataset: tf.data.Dataset - The dataset containing image-label pairs\n",
    "  model: tf.keras.Model - The trained model to generate predictions\n",
    "  num_samples: int - Number of samples to plot\n",
    "  \"\"\"\n",
    "  # Take samples from the dataset\n",
    "  samples = dataset.take(num_batches)\n",
    "\n",
    "  for images, labels in samples:\n",
    "    # Generate predictions\n",
    "    preds = model.predict(images, verbose=0)\n",
    "    preds = tf.math.argmax(preds, axis=-1)\n",
    "\n",
    "    # Create figure with subplots\n",
    "    batch_size = images.shape[0]\n",
    "    fig, axes = plt.subplots(batch_size, 3, figsize=(15, 5 * batch_size))\n",
    "\n",
    "    if batch_size == 1:\n",
    "      axes = [axes]  # Handle case where batch size is 1\n",
    "\n",
    "    # Define custom colors for each class\n",
    "    import matplotlib.colors as mcolors\n",
    "    class_colors = [\"purple\", \"blue\", \"green\", \"orange\", \"yellow\"]  # Define your colors\n",
    "    cmap = mcolors.ListedColormap(class_colors)\n",
    "\n",
    "    # Define normalization to map class values to the color map\n",
    "    bounds = np.arange(num_classes + 1) - 0.5  # Create boundaries for each class\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "      # Plot original image\n",
    "      axes[i][0].set_title(\"Original Image\")\n",
    "      axes[i][0].imshow(images[i])\n",
    "      axes[i][0].axis('off')\n",
    "\n",
    "      # Plot original mask\n",
    "      axes[i][1].set_title(\"Original Mask\")\n",
    "      axes[i][1].imshow(labels[i], cmap=cmap, norm=norm)\n",
    "      axes[i][1].axis('off')\n",
    "\n",
    "      # Plot predicted mask\n",
    "      axes[i][2].set_title(\"Predicted Mask\")\n",
    "      axes[i][2].imshow(preds[i], cmap=cmap, norm=norm)\n",
    "      axes[i][2].axis('off')\n",
    "\n",
    "    # Add a colorbar\n",
    "    cbar = fig.colorbar(\n",
    "      plt.cm.ScalarMappable(cmap=cmap, norm=norm),\n",
    "      ax=axes[:, 1],  # Align the colorbar with the mask columns\n",
    "      orientation=\"vertical\",\n",
    "      fraction=0.02,\n",
    "      pad=0.04\n",
    "    )\n",
    "    cbar.set_ticks(np.arange(num_classes))  # Set tick locations\n",
    "    cbar.set_ticklabels([f\"Class {i}\" for i in range(num_classes)])  # Set tick labels\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miou = MeanIntersectionOverUnion(num_classes=NUM_CLASSES, labels_to_exclude=[0])\n",
    "\n",
    "if not model_filename_override:\n",
    "  model = model_dict[model_name](IMG_SIZE + (1,), NUM_CLASSES)\n",
    "  histories = []\n",
    "\n",
    "  for ts in training_schedule:\n",
    "    model.compile(loss=get_loss(),\n",
    "                  optimizer=get_optimizer(batch_size=ts['batch_size'], lr = ts['lr'], opt=ts['opt_name']), \n",
    "                  metrics=['accuracy', miou])\n",
    "    display_model(model)\n",
    "    val_data_loader = get_dataset(X_val, y_val, batch_size=ts['batch_size'])\n",
    "    if ts['augmentation']:\n",
    "      if ts.get('enlarge_dataset_with_custom_np_ds', False):\n",
    "        # This example enlarges the images with a lot of bg labels (>=90%)\n",
    "        bg_augmented_data = get_enlarged_dataset(noisy_images[0][0], noisy_images[0][1], build_augmentation_bg)\n",
    "        # You can add additional data and then using additional_ds_concat=[bg_augmented_data, ...]\n",
    "        data_loader = get_dataset(X_train, y_train, \n",
    "                                  batch_size=ts['batch_size'], \n",
    "                                  augmentations=apply_augmentation,\n",
    "                                  augmentation_repetition=ts['augmentation_repetition'], \n",
    "                                  concat_and_shuffle_aug_with_no_aug=ts['include_non_augmented'], additional_ds_concat=[bg_augmented_data])\n",
    "        print(f\"Training with augmentation x{ts['augmentation_repetition']}, enlarge_dataset_with_custom_np_ds and {'none ' if not ts['include_non_augmented'] else ''}non-augmented data.\")\n",
    "      else:\n",
    "        data_loader = get_dataset(X_train, y_train, \n",
    "                                  batch_size=ts['batch_size'], \n",
    "                                  augmentations=apply_augmentation,\n",
    "                                  augmentation_repetition=ts['augmentation_repetition'], \n",
    "                                  concat_and_shuffle_aug_with_no_aug=ts['include_non_augmented'])\n",
    "        print(f\"Training with augmentation x{ts['augmentation_repetition']} and {'none ' if not ts['include_non_augmented'] else ''}non-augmented data.\")\n",
    "    else:\n",
    "      data_loader = get_dataset(X_train, y_train, batch_size=ts['batch_size'])\n",
    "      print(f'Fitting model without augmentation')\n",
    "    fit_history = fit_model(model, \n",
    "                            data_loader=data_loader, \n",
    "                            validation_data_loader=val_data_loader,\n",
    "                            epochs = ts['epochs'])\n",
    "    histories.append(fit_history)\n",
    "\n",
    "  # Calculate and print the final validation accuracy\n",
    "  final_val_meanIoU = round(max(histories[-1]['val_mean_iou'])* 100, 2)\n",
    "  print(f'Final validation Mean Intersection Over Union: {final_val_meanIoU}%')\n",
    "\n",
    "  # Save intermediate model\n",
    "  model_filename = f'{model_name}-{str(final_val_meanIoU)}-{datetime.now().strftime(\"%y%m%d_%H%M\")}.keras'\n",
    "  model.save(model_filename)\n",
    "\n",
    "  # Free memory by deleting the model instance\n",
    "  if FREE_MODEL:\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_filename_override:\n",
    "  for fit_history in histories:\n",
    "    plot_training(fit_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the segmentation model\n",
    "test_dataset = get_dataset(X_test, y_test, batch_size=8)\n",
    "\n",
    "if model_filename_override:\n",
    "  model = tfk.models.load_model(model_filename_override, compile=False)\n",
    "  model.compile(\n",
    "    loss=get_loss(),\n",
    "    optimizer=get_optimizer(),\n",
    "    metrics=[\"accuracy\", miou]\n",
    "  )\n",
    "  display_model(model)\n",
    "\n",
    "# Evaluate the model on the test set and print the results\n",
    "test_loss, test_accuracy, test_mean_iou = model.evaluate(test_dataset, verbose=1)\n",
    "print(f'Test Accuracy: {round(test_accuracy, 4)}')\n",
    "print(f'Test Mean Intersection over Union: {round(test_mean_iou, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_triptychs(test_dataset, model, num_batches=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¥‚ Combine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = tf.keras.models.load_model('binary-cnn79.02.keras') \n",
    "multi_model = tf.keras.models.load_model('multi-cnn90.08.keras')\n",
    "segmentation_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEG_SOURCE = 0\n",
    "CLASS_SOURCE = 1\n",
    "def combined_model(input_data: np.ndarray):\n",
    "  res = []\n",
    "  source = []\n",
    "  prob_bin_model = []\n",
    "  for i in input_data:\n",
    "    # Add batch dimension\n",
    "    i = tf.expand_dims(i, axis=0)  # Shape: (1, 64, 128, 1)\n",
    "    binary_output = binary_model(i)\n",
    "    binary_output = round(float(binary_output[0]), 2)\n",
    "    prob_bin_model.append(binary_output)\n",
    "\n",
    "    if binary_output > 0.1:\n",
    "      seg_out = segmentation_model(i)\n",
    "      res.append(seg_out[0])\n",
    "      source.append(SEG_SOURCE)\n",
    "    else:\n",
    "      multi_out = multi_model(i)\n",
    "      label = tf.argmax(multi_out, axis=-1)\n",
    "      label = tf.fill((1, 64, 128), label)\n",
    "      label = tf.one_hot(label, depth=5)\n",
    "      res.append(label[0])\n",
    "      source.append(CLASS_SOURCE)\n",
    "  return np.array(res), source, prob_bin_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X_test.shape[0]\n",
    "preds, sources, probs = combined_model(X_test[:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data. The number of images being displayed are rows X cols\n",
    "def plot_combined_model(data=None, mask_true=None, mask_pred=None, sources=None, probs=None, num_images=10, num_cls=5, colors=None):\n",
    "  # Define custom colors for each class\n",
    "  import matplotlib.colors as mcolors\n",
    "  class_colors = [\"purple\", \"blue\", \"green\", \"orange\", \"yellow\"] if colors is None else colors\n",
    "  cmap = mcolors.ListedColormap(class_colors)\n",
    "  bounds = np.arange(num_cls + 1) - 0.5  # Create boundaries for each class\n",
    "  norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "  # Plot settings\n",
    "  fig, axes = plt.subplots(num_images, 3, figsize=(8, num_images * 2))\n",
    "\n",
    "  for i in range(num_images):\n",
    "    # Original image\n",
    "    axes[i, 0].imshow(data[i], cmap=\"gray\")\n",
    "    axes[i, 0].set_title(f\"Image {i+1}\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "\n",
    "    # Corresponding mask\n",
    "    axes[i, 1].imshow(mask_true[i], cmap=cmap, norm=norm)  # Adjust cmap as needed\n",
    "    axes[i, 1].set_title(f\"Mask true {i+1}\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "\n",
    "    # Corresponding mask\n",
    "    axes[i, 2].imshow(mask_pred[i], cmap=cmap, norm=norm)  # Adjust cmap as needed\n",
    "    axes[i, 2].set_title(f\"Mask pred {i+1} from source {'SEG' if sources[i] == SEG_SOURCE else 'CLASS'} p={probs[i]}\")\n",
    "    axes[i, 2].axis(\"off\")\n",
    "\n",
    "  # Add a colorbar\n",
    "  cbar = fig.colorbar(\n",
    "    plt.cm.ScalarMappable(cmap=cmap, norm=norm),\n",
    "    ax=axes[:, 1],  # Align the colorbar with the mask columns\n",
    "    orientation=\"vertical\",\n",
    "    fraction=0.02,\n",
    "    pad=0.04\n",
    "  )\n",
    "  cbar.set_ticks(np.arange(num_cls))  # Set tick locations\n",
    "  cbar.set_ticklabels([f\"Class {i}\" for i in range(num_cls)])  # Set tick labels\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_combined_model(X_test[:N], y_test[:N], np.argmax(preds, axis=-1), sources, probs, num_images=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miou = MeanIntersectionOverUnion(num_classes=num_classes, labels_to_exclude=[0])\n",
    "miou.update_state(y_test[:N], preds)\n",
    "miou.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸŽ° Generate submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not loading the model but using the python env model as there is a current error on the `MeanIntersectionOverUnion` class which is not serializable making the model not loadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(hidden_X_test.shape)\n",
    "#preds, sources, probs = combined_model(hidden_X_test)\n",
    "preds = model.predict(hidden_X_test)\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "\n",
    "def y_to_df(y) -> pd.DataFrame:\n",
    "  \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n",
    "  n_samples = len(y)\n",
    "  y_flat = y.reshape(n_samples, -1)\n",
    "  df = pd.DataFrame(y_flat)\n",
    "  df[\"id\"] = np.arange(n_samples)\n",
    "  cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n",
    "  return df[cols]\n",
    "\n",
    "submission_filename = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M\")}.csv'\n",
    "submission_df = y_to_df(preds)\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "print('Submission saved in', submission_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPhN8z97sycURDAjAFsp+EI",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6047840,
     "sourceId": 9855285,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6047865,
     "sourceId": 9855319,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 159775,
     "modelInstanceId": 137060,
     "sourceId": 161170,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 162416,
     "modelInstanceId": 139795,
     "sourceId": 164339,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 164634,
     "modelInstanceId": 142056,
     "sourceId": 166955,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 165351,
     "modelInstanceId": 142773,
     "sourceId": 167821,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 170852,
     "modelInstanceId": 148341,
     "sourceId": 174251,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "anndl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
